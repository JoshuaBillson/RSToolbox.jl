var documenterSearchIndex = {"docs":
[{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"preprocessing_example/#Preprocessing-Example","page":"Preprocessing Example","title":"Preprocessing Example","text":"","category":"section"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"In remote sensing, we often want to preprocess our imagery before using it in further analysis. For example, we may want to convert digital numbers to surface reflectance, crop to a region of interest, or cut our image into manageable tiles before feeding it into a machine learning algorithm. The first step is to read our data from disk. A variety of commons sensors are supported by RemoteSensingToolbox, but today we're going to be working with Landsat 8 imagery.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"using RemoteSensingToolbox, Rasters, Images\nusing Pipe: @pipe\n\nlandsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\")","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"Most remote sensing images encode each pixel as a Digital Number (DN). Unfortunately, this is not very interpretable for a variety of applications, particularly in the case of land cover classification. A much better measurement is reflectance, which is defined as a number between 0 and 1, which indicates the fraction of light that is reflected by the observed surface. The specifics of converting from DN to reflectance differs from one sensor to the next. Fortunately, all AbstractSensor types contain this information implicitly. Thus, we can simple call dn_to_reflectance to turn our DNs to surface reflectance.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"landsat_sr = dn_to_reflectance(landsat)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"When we visualize our data, we observe the present of a large number of clouds.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"visualize(landsat_sr, TrueColor; upper=0.90)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"In many applications, we need to remove all pixels covered by clouds before further processing. Fortunately, Landsat images comes with a Quality Assurance (QA) file which, among other things, gives us a mask of all detected cloud pixels. However, this data is not easy to interpret, as each mask is encided as a specific bit in an unsigned 16 bit integer. RemoteSensingToolbox provides the landsat_qa method to decode the QA image into a more interpretable form.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"qa = landsat_qa(\"LC08_L2SP_043024_20200802_20200914_02_T1/LC08_L2SP_043024_20200802_20200914_02_T1_QA_PIXEL.TIF\")","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"RasterStack with dimensions: \n  X Projected{Float64} LinRange{Float64}(493785.0, 728385.0, 7821) ForwardOrdered Regular Points crs: WellKnownText,\n  Y Projected{Float64} LinRange{Float64}(5.84638e6, 5.60878e6, 7921) ReverseOrdered Regular Points crs: WellKnownText\nand 8 layers:\n  :fill          UInt8 dims: X, Y (7821×7921)\n  :dilated_cloud UInt8 dims: X, Y (7821×7921)\n  :cirrus        UInt8 dims: X, Y (7821×7921)\n  :cloud         UInt8 dims: X, Y (7821×7921)\n  :cloud_shadow  UInt8 dims: X, Y (7821×7921)\n  :snow          UInt8 dims: X, Y (7821×7921)\n  :clear         UInt8 dims: X, Y (7821×7921)\n  :water         UInt8 dims: X, Y (7821×7921)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"Now that we have the QA masks, we can use the mask_pixels method to remove the presence of clouds and cloud shadows.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"@pipe mask_pixels(landsat_sr, qa[:cloud]) |> \nmask_pixels(_, qa[:cloud_shadow]) |> \nvisualize(_, TrueColor)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"Next, let's crop our rasters to a region of interest. All AbstractSensor types are compatible with the standard view and index operations supported by Rasters.jl.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"roi = @view landsat_sr[X(5801:6800), Y(2201:3200)]","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"Remotely sensed imagery is often too large to be used directly in machine learning applications. Thus, it is common practice to cut a raster into several smaller tiles, which may partially overlap with one another to increase the number of samples available to us. This can be accomplished with the create_tiles method, which provides an optional stride argument specifying how far apart each tile should be in the x and y dimensions. By default, stride is equal to the tile size, but setting stride to a smaller value allows us to generate overlapping tiles.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"tiles = create_tiles(roi, (500, 500))\noverlapping_tiles = create_tiles(roi, (500, 500); stride=(250, 250))","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"To better understand how create_tiles works, let's visualize the result of generating non-overlapping and half-overlapping tiles.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"@pipe tiles |> \nvisualize.(_, TrueColor; upper=0.998) |> \nmosaicview(_, ncol=2, rowmajor=true, npad=5, fillvalue=1.0)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"@pipe overlapping_tiles |> \nvisualize.(_, TrueColor; upper=0.998) |> \nmosaicview(_, ncol=2, rowmajor=true, npad=5, fillvalue=1.0)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"Finally, we're ready to save our tiles to disk. However, instead of saving each band as a separate file, we can combine them into a single multi-band raster. To do so, we use the tocube method, which optionally takes a list of layers that we want to write to the raster. By default, all layers are included. In this example, we will keep only the blue, green, red, and nir bands for each tile.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing Example","title":"Preprocessing Example","text":"cubes = map(x -> tocube(x; layers=[:B2, :B3, :B4, :B5]), tiles)\nfor (i, cube) in enumerate(cubes)\n   Rasters.write(\"tile_$i.tif\", cube)\nend","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"quickstart/#Quickstart-Example","page":"Quick Start","title":"Quickstart Example","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"RemoteSensingToolbox provides a number of utilities for visualizing, manipulating, and interpreting remotely sensed imagery. First, lets load the imagery we want to work with. We're using Landsat 8 imagery in this example, so we'll pass the Landsat8 type to read_bands so it knows how to parse the relevant files from the provided directory. Landsat8 is an instance of AbstractBandset, which is the supertype responsible for allowing many methods within RemoteSensingToolbox to infer sensor-specific information by exploiting Julia's multiple dispatch system.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"using RemoteSensingToolbox, Rasters\nusing Pipe: @pipe\n\nlandsat = read_bands(Landsat8, \"LC08_L2SP_043024_20200802_20200914_02_T1/\")","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Now let's visualize our data to see what we're working with. This is where the power of AbstractBandset can first be demonstrated. To view a true color composite of the data, we need to know the bands corresponding to red, green, and blue. However, it would be tedious to memorize and manually specify this information whenever we want to call a method which relies on a specific combination of bands. Fortunately, all AbstractBandset types know this information implicitly, so all we need to do is pass in Landsat8 as a parameter to TrueColor.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"visualize(landsat, TrueColor{Landsat8}; upper=0.90)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"You may have noticed that we provided an additional argument upper to the visualize method. This parameter controls the upper quantile to be used when performing histogram stretching to make the imagery interpretable to humans. This parameter is set to 0.98 by default, but because our scene contains a significant number of bright clouds, we need to lower it to prevent the image from appearing too dark. We can remove these clouds by first loading the Quality Assurance (QA) mask that came with our landsat product and then calling mask_pixels.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"qa = read_qa(Landsat8, \"LC08_L2SP_043024_20200802_20200914_02_T1/\")\n\nmasked_landsat = @pipe mask_pixels(landsat, qa[:cloud]) |> mask_pixels(_, qa[:cloud_shadow])\n\nvisualize(masked_landsat, TrueColor{Landsat8})","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Now let's try to visualize some other band combinations. The Agriculture band comination is commonly used to distinguish regions with healthy vegetation, which appear as various shades of green.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"visualize(landsat, Agriculture{Landsat8}; upper=0.90)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We can also convert Digital Numbers (DNs) to reflectance by calling dn_to_reflectance and passing in the appropriate bandset.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"landsat_sr = dn_to_reflectance(landsat, Landsat8)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We'll finish this example by demonstrating how to compute land cover indices with any AbstractBandset type. The Modified Normalized Difference Water Index (MNDWI) is used to help distinguish water from land. Here, we visualize both the true color representation and the corresponding MNDWI index.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"roi = @view landsat_sr[X(5800:6800), Y(2200:3200)]\n\ntrue_color = visualize(roi, TrueColor{Landsat8}; upper=0.998)\n\nindex = mndwi(roi, Landsat8) |> visualize\n\nmosaicview(true_color, index; npad=5, fillvalue=0.0, ncol=2)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"spectral_example/#Spectral-Analysis-Example","page":"Spectral Analysis","title":"Spectral Analysis Example","text":"","category":"section"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"A common application of remotely sensed imagery is land cover classification. One method to accomplish this is to analyze the spectral signatures produced by different types of cover. RemoteSensingToolbox provides a number of functions for extracting and visualyzing spectral signatures organized by their associated lan cover.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"The first step in our analysis is to load our remotely sensed data and convert the DNs (Digital Numbers) to reflectances. Reflectance is a standardized unit of measurement defined over the interval [0, 1] which denotes the fraction of light that is reflected by the observed surface. A reflectance of 0.0 indicates that no light was reflected whereas a reflectance of 1.0 indicates that 100% of light was reflected.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"using RemoteSensingToolbox, DataFrames, Shapefile, CairoMakie\n\nlandsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\") |> dn_to_reflectance","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Next, we need to load a shapefile which defines some regions containing each type of land cover that we're interested in.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"shp = Shapefile.Table(\"data/landcover/landcover.shp\") |> DataFrame","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Examining the shapefile gives us some idea of how its contents are structured. As we can see, the regions of interest are stored as Polygon objects under the :geometry column, while the land cover types are under :MC_name and :C_name. The :MC_name column defines the macroclass, which in our case are built up land, vegetation, bare earth, and water. The :C_name column defines the specific class to which some land cover belongs. For example, both \"Trees\" and \"Vegetation\" belong to the \"Vegetation\" macroclass.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"8×7 DataFrame\n Row │ geometry            fid      MC_ID  MC_name     C_ID   C_name      SCP_UID                   \n     │ Polygon             Missing  Int64  String      Int64  String      String                    \n─────┼──────────────────────────────────────────────────────────────────────────────────────────────\n   1 │ Polygon(38 Points)  missing      1  Built Up        1  Built Up    20230527_122212594060_314\n   2 │ Polygon(31 Points)  missing      1  Built Up        2  Road        20230527_122301732906_304\n   3 │ Polygon(7 Points)   missing      2  Vegetation      3  Vegetation  20230527_122832068862_302\n   4 │ Polygon(57 Points)  missing      2  Vegetation      4  Trees       20230527_123221462871_572\n   5 │ Polygon(5 Points)   missing      3  Bare Earth      5  Hail Scar   20230527_123631491671_937\n   6 │ Polygon(7 Points)   missing      3  Bare Earth      6  Bare Earth  20230527_123727873290_779\n   7 │ Polygon(7 Points)   missing      4  Water           7  Lake        20230527_123931189139_867\n   8 │ Polygon(5 Points)   missing      3  Bare Earth      6  Bare Earth  20230527_125120033074_286","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"To visualize the spectral signatures of each type of land cover, we can call plot_signatures on the raster from which we want to extract the signatures, the shapefile defining the regions of interest, and the column which specifies the class of each polygon. We should note that plot_signatures also expects a BandSet defining the sensor's bands and corresponding central wavelength. However, this information is determined implicitly for AbstractSensor types.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"plot_signatures(landsat, shp, :C_name)","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"We see that we've plotted the signatures for each land cover type in shp. However, we may wish to override the default colors. Fortunately, plot_signatures accepts an optional argument allowing us to specify any colors that we wish.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"plot_signatures(landsat, shp, :C_name; colors=cgrad(:tab10))","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"The plot_signatures! method is nearly identical to plot_signatures, but it expects a Makie.Axis object as its first argument onto which the signatures will be drawn (hence the exclamation). This allows us to create more complicated plots than are supported by plot_signatures. We will demonstrate this capability by plotting the same signatures for three different sensors, each of which passed over our study area within a period of four days. For this reason, we can compare the signatures with a single shapefile, as we do not expect the land cover types to change significantly within this span of time.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"# Load Sentinel and DESIS\nsentinel = Sentinel2A(\"data/T11UPT_20200804T183919/\") |> dn_to_reflectance\ndesis = DESIS(\"data/DESIS-HSI-L2A-DT0483531728_001-20200804T234520-V0210/SPECTRAL_IMAGE.tif\") |> dn_to_reflectance\nsensors = [landsat, sentinel, desis]\n\n# Create Figure\nfig = Figure(resolution=(1000, 800))\n\n# Create Axes\nax1 = Axis(fig[1,1], xticksvisible=false, xticklabelsvisible=false)\nax2 = Axis(fig[2,1], ylabel=\"Reflectance\", ylabelfont=:bold, xticksvisible=false, xticklabelsvisible=false)\nax3 = Axis(fig[3,1], xlabel=\"Wavelength (nm)\", xlabelfont=:bold)\naxs = [ax1, ax2, ax3]\n\n# Plot Signatures\ncolors = cgrad([:orange, :green, :saddlebrown, :navy], 4, categorical=true)\nfor (sensor, ax) in zip(sensors, axs)\n   plot_signatures!(ax, sensor, shp, :MC_name; colors=colors)\n   xlims!(ax, 400, 1000)\nend\n\n# Add Legend\nLegend(fig[1:3,2], first(axs), \"Classification\")","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"#RemoteSensingToolbox","page":"Home","title":"RemoteSensingToolbox","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RemoteSensingToolbox is a pure Julia package intended to provide a collection of tools for visualizing, manipulating, and interpreting remotely sensed imagery.","category":"page"},{"location":"","page":"Home","title":"Home","text":"RemoteSensingToolbox provides a number of utilities for . First, lets load the imagery we want to work with. We're using Landsat 8 imagery in this example, so we'll pass the Landsat8 type to read_bands so it knows how to parse the relevant files from the provided directory. Landsat8 is an instance of AbstractBandset, which is the supertype responsible for allowing many methods within RemoteSensingToolbox to infer sensor-specific information by exploiting Julia's multiple dispatch system.","category":"page"},{"location":"#Bandsets","page":"Home","title":"Bandsets","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Bandsets are julia types that encode the sensor-specific information needed for many methods in RemoteSensingToolbox to work without the need for tedious details provided by the end user. ","category":"page"},{"location":"","page":"Home","title":"Home","text":" \nBase.getindex return the layer correspinding to the given band name.\nBase.length return the number of layers in the enclosed Rasters.RasterStack.\nBase.map apply a function to each layer in the enclosed Rasters.RasterStack.\nBase.write write layers to file.\nRasters.resample resample data to a different size and projection, or snap to another object.\nRasters.crop shrink objects to specific dimension sizes or the extent of another object.\nRasters.extend extend objects to specific dimension sizes or the extent of another object.\nRasters.trim trims areas of missing values for arrays and across stack layers.\nRasters.mask mask an object by a polygon or Raster along X/Y, or other dimensions.\nRasters.replace_missing replace all missing values in an object and update missingval.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Additionally, asraster can be used to apply a function to the enclosed Rasters.RasterStack.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Sensors]","category":"page"},{"location":"#Visualization","page":"Home","title":"Visualization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"visualization.jl\"]","category":"page"},{"location":"#RemoteSensingToolbox.Agriculture","page":"Home","title":"RemoteSensingToolbox.Agriculture","text":"Agriculture band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.ColorInfrared","page":"Home","title":"RemoteSensingToolbox.ColorInfrared","text":"Color infrared band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Geology","page":"Home","title":"RemoteSensingToolbox.Geology","text":"Geology band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.SWIR","page":"Home","title":"RemoteSensingToolbox.SWIR","text":"SWIR band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.TrueColor","page":"Home","title":"RemoteSensingToolbox.TrueColor","text":"True color band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox._linear_stretch-Tuple{Rasters.AbstractRaster, Any, Any}","page":"Home","title":"RemoteSensingToolbox._linear_stretch","text":"Adjust image histogram by performing a linear stretch to squeeze all values between the percentiles lower and upper into the range [0,1].\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox._raster_to_image-Tuple{Rasters.Raster}","page":"Home","title":"RemoteSensingToolbox._raster_to_image","text":"Turn a raster into an image compatible with Images.jl.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.visualize-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.visualize","text":"visualize(g::AbstractRaster; lower=0.02, upper=0.98)\nvisualize(r::AbstractRaster, g::AbstractRaster, b::AbstractRaster; lower=0.02, upper=0.98)\nvisualize(img::AbstractBandSet, ::Type{TrueColor{AbstractBandset}}; kwargs...)\nvisualize(img::AbstractBandSet, ::Type{ColorInfrared{AbstractBandset}}; kwargs...)\nvisualize(img::AbstractBandSet, ::Type{SWIR{AbstractBandset}}; kwargs...)\nvisualize(img::AbstractBandSet, ::Type{Agriculture{AbstractBandset}}; kwargs...)\nvisualize(img::AbstractBandSet, ::Type{Geology{AbstractBandset}}; kwargs...)\n\nVisualize a satellite image after applying a histogram stretch. Returns either an RGB or grayscale image compatible with the Images.jl ecosystem.\n\nA number of band combinations are supported for types implementing the AbstractBandSet interface.\n\nExample 1\n\nlandsat = read(Landsat8, \"LC08_L2SP_043024_20200802_20200914_02_T1/\")\nimg = mndwi(landsat, Landsat8) |> visualize\nsave(\"mndwi.png\", img)\n\nExample 2\n\nlandsat = read(Landsat8, \"LC08_L2SP_043024_20200802_20200914_02_T1/\")\nimg = visualize(landsat, TrueColor{Landsat8}; upper=0.90)\nsave(\"truecolor.png\", img)\n\n\n\n\n\n","category":"method"},{"location":"#Preprocessing","page":"Home","title":"Preprocessing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"preprocessing.jl\"]","category":"page"},{"location":"#RemoteSensingToolbox.create_tiles-Tuple{Any, Tuple{Int64, Int64}}","page":"Home","title":"RemoteSensingToolbox.create_tiles","text":"create_tiles(raster, tile::Tuple{Int,Int}; stride=tile)\n\nSlice the given raster into tiles with size tile.\n\nParameters\n\nraster: The raster to be cut into tiles.\ntile: The size of the generated tiles in terms of width x height.\nstride: The distance between the top-left corner of each tile. Is equal to tile by default, which produces non-overlapping tiles.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.mask_pixels!-Tuple{Rasters.AbstractRaster, Any}","page":"Home","title":"RemoteSensingToolbox.mask_pixels!","text":"mask_pixels!(raster, mask; invert_mask=false)\n\nDrop pixels from a raster according to a given mask. The mask and raster must have the same extent and size.\n\nParameters\n\nraster: The raster to be masked.\nmask: A mask defining which pixels we want to drop. By default, we drop pixels corresponding to mask values of 1.\ninvert_mask: Treat mask values of 1 as 0 and vice-versa.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.mask_pixels-Tuple{Rasters.AbstractRaster, Any}","page":"Home","title":"RemoteSensingToolbox.mask_pixels","text":"mask_pixels(raster, mask; invert_mask=false)\n\nDrop pixels from a raster according to a given mask. The mask and raster must have the same extent and size.\n\nParameters\n\nraster: The raster to be masked.\nmask: A mask defining which pixels we want to drop. By default, we drop pixels corresponding to mask values of 1.\ninvert_mask: Treat mask values of 1 as 0 and vice-versa.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.tocube-Tuple{Rasters.RasterStack}","page":"Home","title":"RemoteSensingToolbox.tocube","text":"tocube(rs::RasterStack; layers=names(rs))\ntocube(rs::AbstractBandset; layers=names(rs))\n\nTransform the multi-layer RasterStack to a multi-band raster.\n\nParameters\n\nX: The RasterStack or AbstractBandset to be transformed into a multi-band raster.\nlayers: The layers to include in the new raster.\n\nExample\n\njulia> landsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1\");\njulia> tocube(landsat)\n7821×7921×7 Raster{Float32,3} B1 with dimensions: \n  X Projected{Float64} LinRange{Float64}(493785.0, 728385.0, 7821) ForwardOrdered Regular Points crs: WellKnownText,\n  Y Projected{Float64} LinRange{Float64}(5.84638e6, 5.60878e6, 7921) ReverseOrdered Regular Points crs: WellKnownText,\n  Band Categorical{Int64} 1:7 ForwardOrdered\nextent: Extent(X = (493785.0, 728385.0), Y = (5.608785e6, 5.846385e6), Band = (1, 7))\nmissingval: 0.0f0\ncrs: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]\nparent:\n[:, :, 1]\n           5.84638e6  5.84636e6  5.84632e6  5.8463e6  5.84626e6  …  5.60894e6  5.6089e6  5.60888e6  5.60884e6  5.60882e6  5.60878e6\n 493785.0  0.0        0.0        0.0        0.0       0.0           0.0        0.0       0.0        0.0        0.0        0.0\n      ⋮                                               ⋮          ⋱                                             ⋮          \n 728355.0  0.0        0.0        0.0        0.0       0.0           0.0        0.0       0.0        0.0        0.0        0.0\n 728385.0  0.0        0.0        0.0        0.0       0.0           0.0        0.0       0.0        0.0        0.0        0.0\n[and 6 more slices...]\n\n\n\n\n\n","category":"method"},{"location":"#Land-Cover-Indices","page":"Home","title":"Land Cover Indices","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"indices.jl\"]","category":"page"},{"location":"#RemoteSensingToolbox.mndwi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.mndwi","text":"mndwi(green::AbstractRaster, swir::AbstractRaster)\nmndwi(stack::AbstractRasterStack, ::Type{AbstractBandset})\n\nCompute the Modified Normalised Difference Water Index (Xu 2006).\n\nMNDWI = (green - swir) / (green + swir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.nbri-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.nbri","text":"nbri(nir::AbstractRaster, swir2::AbstractRaster)\nnbri(stack::AbstractRasterStack, ::Type{AbstractBandset})\n\nCompute the Normalized Burn Ratio Index.\n\nNBRI is used to emphasize burned areas.\n\nNBRI = (nir - swir2) / (nir + swir2)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndbi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndbi","text":"ndbi(swir1::AbstractRaster, nir::AbstractRaster)\nndbi(stack::AbstractRasterStack, ::Type{AbstractBandset})\n\nCompute the The Normalized Difference Built-up Index\n\nNDBI is used to emphasize urban and built-up areas.\n\nNDBI = (swir1 - nir) / (swir1 + nir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndmi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndmi","text":"ndmi(nir::AbstractRaster, swir1::AbstractRaster)\nndmi(stack::AbstractRasterStack, ::Type{AbstractBandset})\n\nCompute the Normalized Difference Moisture Index.\n\nNDMI is sensitive to the moisture levels in vegetation. It is used to monitor droughts and fuel levels in fire-prone areas.\n\nNDMI = (nir - swir1) / (nir + swir1)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndvi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndvi","text":"ndvi(nir::AbstractRaster, red::AbstractRaster)\nndvi(stack::AbstractRasterStack, ::Type{AbstractBandset})\n\nCompute the Normalized Difference Vegetation Index.\n\nNDVI = (nir - red) / (nir + red)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndwi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndwi","text":"ndwi(green::AbstractRaster, nir::AbstractRaster)\nndwi(stack::AbstractRasterStack, ::Type{AbstractBandset})\n\nCompute the Normalized Difference Water Index (McFeeters 1996).\n\nNDWI = (green - nir) / (green + nir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.savi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.savi","text":"savi(nir::AbstractRaster, red::AbstractRaster; L=0.33)\nsavi(stack::AbstractRasterStack, ::Type{AbstractBandset}; L=0.33)\n\nCompute the Soil Adjusted Vegetation Index (Huete 1988).\n\nSAVI is a vegetation index which attempts to minimize soil brightness influences by introducing a soil-brightness correction factor (L).\n\nL represents the amount of green vegetation cover, which is set to 0.33 by default.\n\nSAVI = ((nir - red) / (nir + red + L)) * (1 + L)\n\n\n\n\n\n","category":"method"},{"location":"#Spectral-Analysis","page":"Home","title":"Spectral Analysis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Spectral]","category":"page"},{"location":"#Transformations","page":"Home","title":"Transformations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Transformations]","category":"page"},{"location":"#RemoteSensingToolbox.Transformations.AbstractTransformation","page":"Home","title":"RemoteSensingToolbox.Transformations.AbstractTransformation","text":"The supertype of all transformations. Subtypes are expected to implement the fit and transform methods.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Transformations.Normalize","page":"Home","title":"RemoteSensingToolbox.Transformations.Normalize","text":"A struct for storing the parameters necessary to perform a normalization transformation.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Transformations.PCA","page":"Home","title":"RemoteSensingToolbox.Transformations.PCA","text":"A struct for storing the parameters necessary to perform a PCA transformation.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Transformations.fit_transform-Tuple{Type{Normalize}, Rasters.AbstractRasterStack}","page":"Home","title":"RemoteSensingToolbox.Transformations.fit_transform","text":"fit_transform(transformation::Type{Normalize}, raster)\n\nFit a PCA transformation to the given raster.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack on which to perform a normalization transformation.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Transformations.fit_transform-Tuple{Type{PCA}, Union{Rasters.AbstractRaster, Rasters.AbstractRasterStack}}","page":"Home","title":"RemoteSensingToolbox.Transformations.fit_transform","text":"fit_transform(transformation::Type{PCA}, raster; components=nbands(raster), method=:cov, stats_fraction=1.0)\n\nFit a PCA transformation to the given raster.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack on which to perform a PCA transformation.\ncomponents: The number of principal components to use.\nmethod: One of either :cov or :cor, depending on whether we want to run PCA on the covariance or the correlation matrix.\nstats_fraction: The fraction of pixels to use in the calculation. Setting stats_fraction < 1 will produce faster but less accurate results. \n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Transformations.fit_transform-Union{Tuple{T}, Tuple{Type{T}, Any}} where T<:AbstractTransformation","page":"Home","title":"RemoteSensingToolbox.Transformations.fit_transform","text":"fit_transform(::Type{<:AbstractTransformation}, raster; kwargs...)\n\nFit a transformation to the given raster.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Transformations.inverse_transform-Union{Tuple{T}, Tuple{T, Any, Vararg{Any}}} where T<:AbstractTransformation","page":"Home","title":"RemoteSensingToolbox.Transformations.inverse_transform","text":"inverse_transform(transformation::AbstractTransformation, raster)\n\nUndo a previously applied transformation.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Transformations.transform-Tuple{Normalize, Rasters.AbstractRasterStack}","page":"Home","title":"RemoteSensingToolbox.Transformations.transform","text":"transform(transformation::Normalize, raster)\n\nPerform a PCA transformation to the given raster.\n\nParameters\n\ntransformation: The fitted Normalize transformation to apply.\nraster: The AbstractRaster or AbstractRasterStack on which to perform a normalization transformation.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Transformations.transform-Tuple{PCA, Rasters.AbstractRasterStack}","page":"Home","title":"RemoteSensingToolbox.Transformations.transform","text":"transform(transformation::PCA, raster)\n\nPerform a PCA transformation to the given raster.\n\nParameters\n\ntransformation: The fitted PCA transformation to apply.\nraster: The AbstractRaster or AbstractRasterStack on which to perform a PCA transformation.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Transformations.transform-Union{Tuple{T}, Tuple{T, Any}} where T<:AbstractTransformation","page":"Home","title":"RemoteSensingToolbox.Transformations.transform","text":"transform(transformation::AbstractTransformation, raster)\n\nApply a transformation to the given raster.\n\n\n\n\n\n","category":"method"}]
}
