var documenterSearchIndex = {"docs":
[{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"preprocessing_example/#Preprocessing-Example","page":"Preprocessing","title":"Preprocessing Example","text":"","category":"section"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"In remote sensing, we often want to preprocess our imagery before using it in further analysis. For example, we may want to convert digital numbers to surface reflectance, crop to a region of interest, or cut our image into manageable tiles before feeding it into a machine learning algorithm. The first step is to read our data from disk. A variety of commons sensors are supported by RemoteSensingToolbox, but today we're going to be working with Landsat 8 imagery.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"using RemoteSensingToolbox, Rasters, Images\nusing Pipe: @pipe\n\nlandsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\")","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"Most remote sensing images encode each pixel as a Digital Number (DN). Unfortunately, this is not very interpretable for a variety of applications, particularly in the case of land cover classification. A much better measurement is reflectance, which is defined as a number between 0 and 1, which indicates the fraction of light that is reflected by the observed surface. The specifics of converting from DN to reflectance differs from one sensor to the next. Fortunately, all AbstractSensor types contain this information implicitly. Thus, we can simple call dn_to_reflectance to turn our DNs to surface reflectance.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"landsat_sr = dn_to_reflectance(landsat)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"When we visualize our data, we observe the present of a large number of clouds.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"visualize(landsat_sr, TrueColor; upper=0.90)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"In many applications, we need to remove all pixels covered by clouds before further processing. Fortunately, Landsat images comes with a Quality Assurance (QA) file which, among other things, gives us a mask of all detected cloud pixels. However, this data is not easy to interpret, as each mask is encided as a specific bit in an unsigned 16 bit integer. RemoteSensingToolbox provides the landsat_qa method to decode the QA image into a more interpretable form.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"qa = landsat_qa(\"LC08_L2SP_043024_20200802_20200914_02_T1/LC08_L2SP_043024_20200802_20200914_02_T1_QA_PIXEL.TIF\")","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"RasterStack with dimensions: \n  X Projected{Float64} LinRange{Float64}(493785.0, 728385.0, 7821) ForwardOrdered Regular Points crs: WellKnownText,\n  Y Projected{Float64} LinRange{Float64}(5.84638e6, 5.60878e6, 7921) ReverseOrdered Regular Points crs: WellKnownText\nand 8 layers:\n  :fill          UInt8 dims: X, Y (7821×7921)\n  :dilated_cloud UInt8 dims: X, Y (7821×7921)\n  :cirrus        UInt8 dims: X, Y (7821×7921)\n  :cloud         UInt8 dims: X, Y (7821×7921)\n  :cloud_shadow  UInt8 dims: X, Y (7821×7921)\n  :snow          UInt8 dims: X, Y (7821×7921)\n  :clear         UInt8 dims: X, Y (7821×7921)\n  :water         UInt8 dims: X, Y (7821×7921)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"Now that we have the QA masks, we can use the mask_pixels method to remove the presence of clouds and cloud shadows.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"@pipe mask_pixels(landsat_sr, qa[:cloud]) |> \nmask_pixels(_, qa[:cloud_shadow]) |> \nvisualize(_, TrueColor)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"Next, let's crop our rasters to a region of interest. All AbstractSensor types are compatible with the standard view and index operations supported by Rasters.jl.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"roi = @view landsat_sr[X(5801:6800), Y(2201:3200)]","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"Remotely sensed imagery is often too large to be used directly in machine learning applications. Thus, it is common practice to cut a raster into several smaller tiles, which may partially overlap with one another to increase the number of samples available to us. This can be accomplished with the create_tiles method, which provides an optional stride argument specifying how far apart each tile should be in the x and y dimensions. By default, stride is equal to the tile size, but setting stride to a smaller value allows us to generate overlapping tiles.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"tiles = create_tiles(roi, (500, 500))\noverlapping_tiles = create_tiles(roi, (500, 500); stride=(250, 250))","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"To better understand how create_tiles works, let's visualize the result of generating non-overlapping and half-overlapping tiles.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"@pipe tiles |> \nvisualize.(_, TrueColor; upper=0.998) |> \nmosaicview(_, ncol=2, rowmajor=true, npad=5, fillvalue=1.0)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"@pipe overlapping_tiles |> \nvisualize.(_, TrueColor; upper=0.998) |> \nmosaicview(_, ncol=2, rowmajor=true, npad=5, fillvalue=1.0)","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"(Image: )","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"Finally, we're ready to save our tiles to disk. However, instead of saving each band as a separate file, we can combine them into a single multi-band raster. To do so, we use the tocube method, which optionally takes a list of layers that we want to write to the raster. By default, all layers are included. In this example, we will keep only the blue, green, red, and nir bands for each tile.","category":"page"},{"location":"preprocessing_example/","page":"Preprocessing","title":"Preprocessing","text":"cubes = map(x -> tocube(x; layers=[:B2, :B3, :B4, :B5]), tiles)\nfor (i, cube) in enumerate(cubes)\n   Rasters.write(\"tile_$i.tif\", cube)\nend","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"spectral_example/#Spectral-Analysis-Example","page":"Spectral Analysis","title":"Spectral Analysis Example","text":"","category":"section"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"A common application of remotely sensed imagery is land cover classification. One method to accomplish this is to analyze the spectral signatures produced by different types of cover. RemoteSensingToolbox provides a number of functions for extracting and visualyzing spectral signatures organized by their associated lan cover.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"The first step in our analysis is to load our remotely sensed data and convert the DNs (Digital Numbers) to reflectances. Reflectance is a standardized unit of measurement defined over the interval [0, 1] which denotes the fraction of light that is reflected by the observed surface. A reflectance of 0.0 indicates that no light was reflected whereas a reflectance of 1.0 indicates that 100% of light was reflected.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"using RemoteSensingToolbox, DataFrames, Shapefile, CairoMakie\n\nlandsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\") |> dn_to_reflectance","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Next, we need to load a shapefile which defines some regions containing each type of land cover that we're interested in.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"shp = Shapefile.Table(\"data/landcover/landcover.shp\") |> DataFrame","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Examining the shapefile gives us some idea of how its contents are structured. As we can see, the regions of interest are stored as Polygon objects under the :geometry column, while the land cover types are under :MC_name and :C_name. The :MC_name column defines the macroclass, which in our case are built up land, vegetation, bare earth, and water. The :C_name column defines the specific class to which some land cover belongs. For example, both \"Trees\" and \"Vegetation\" belong to the \"Vegetation\" macroclass.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"8×7 DataFrame\n Row │ geometry            fid      MC_ID  MC_name     C_ID   C_name      SCP_UID                   \n     │ Polygon             Missing  Int64  String      Int64  String      String                    \n─────┼──────────────────────────────────────────────────────────────────────────────────────────────\n   1 │ Polygon(38 Points)  missing      1  Built Up        1  Built Up    20230527_122212594060_314\n   2 │ Polygon(31 Points)  missing      1  Built Up        2  Road        20230527_122301732906_304\n   3 │ Polygon(7 Points)   missing      2  Vegetation      3  Vegetation  20230527_122832068862_302\n   4 │ Polygon(57 Points)  missing      2  Vegetation      4  Trees       20230527_123221462871_572\n   5 │ Polygon(5 Points)   missing      3  Bare Earth      5  Hail Scar   20230527_123631491671_937\n   6 │ Polygon(7 Points)   missing      3  Bare Earth      6  Bare Earth  20230527_123727873290_779\n   7 │ Polygon(7 Points)   missing      4  Water           7  Lake        20230527_123931189139_867\n   8 │ Polygon(5 Points)   missing      3  Bare Earth      6  Bare Earth  20230527_125120033074_286","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"To visualize the spectral signatures of each type of land cover, we can call plot_signatures on the raster from which we want to extract the signatures, the shapefile defining the regions of interest, and the column which specifies the class of each polygon. We should note that plot_signatures also expects a BandSet defining the sensor's bands and corresponding central wavelength. However, this information is determined implicitly for AbstractSensor types.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"plot_signatures(landsat, shp, :C_name)","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"We see that we've plotted the signatures for each land cover type in shp. However, we may wish to override the default colors. Fortunately, plot_signatures accepts an optional argument allowing us to specify any colors that we wish.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"plot_signatures(landsat, shp, :C_name; colors=cgrad(:tab10))","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"The plot_signatures! method is nearly identical to plot_signatures, but it expects a Makie.Axis object as its first argument onto which the signatures will be drawn (hence the exclamation). This allows us to create more complicated plots than are supported by plot_signatures. We will demonstrate this capability by plotting the same signatures for three different sensors, each of which passed over our study area within a period of four days. For this reason, we can compare the signatures with a single shapefile, as we do not expect the land cover types to change significantly within this span of time.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"# Load Sentinel and DESIS\nsentinel = Sentinel2A(\"data/T11UPT_20200804T183919/\") |> dn_to_reflectance\ndesis = DESIS(\"data/DESIS-HSI-L2A-DT0483531728_001-20200804T234520-V0210/SPECTRAL_IMAGE.tif\") |> dn_to_reflectance\nsensors = [landsat, sentinel, desis]\n\n# Create Figure\nfig = Figure(resolution=(1000, 800))\n\n# Create Axes\nax1 = Axis(fig[1,1], xticksvisible=false, xticklabelsvisible=false)\nax2 = Axis(fig[2,1], ylabel=\"Reflectance\", ylabelfont=:bold, xticksvisible=false, xticklabelsvisible=false)\nax3 = Axis(fig[3,1], xlabel=\"Wavelength (nm)\", xlabelfont=:bold)\naxs = [ax1, ax2, ax3]\n\n# Plot Signatures\ncolors = cgrad([:orange, :green, :saddlebrown, :navy], 4, categorical=true)\nfor (sensor, ax) in zip(sensors, axs)\n   plot_signatures!(ax, sensor, shp, :MC_name; colors=colors)\n   xlims!(ax, 400, 1000)\nend\n\n# Add Legend\nLegend(fig[1:3,2], first(axs), \"Classification\")","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"#RemoteSensingToolbox","page":"Home","title":"RemoteSensingToolbox","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RemoteSensingToolbox is a pure Julia package intended to provide a collection of commonly used tools for working with remotely sensed imagery.","category":"page"},{"location":"#Sensors","page":"Home","title":"Sensors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Sensors are julia structs that wrap a typical Rasters.RasterStack object to provide compatability with many RemoteSensingToolbox algorithms and methods.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The following methods are supported by all AbstractSensor types:","category":"page"},{"location":"","page":"Home","title":"Home","text":" \nBase.getindex return the layer correspinding to the given band name.\nBase.length return the number of layers in the enclosed Rasters.RasterStack.\nBase.map apply a function to each layer in the enclosed Rasters.RasterStack.\nBase.write write layers to file.\nRasters.resample resample data to a different size and projection, or snap to another object.\nRasters.crop shrink objects to specific dimension sizes or the extent of another object.\nRasters.extend extend objects to specific dimension sizes or the extent of another object.\nRasters.trim trims areas of missing values for arrays and across stack layers.\nRasters.mask mask an object by a polygon or Raster along X/Y, or other dimensions.\nRasters.replace_missing replace all missing values in an object and update missingval.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Additionally, asraster can be used to apply a function to the enclosed Rasters.RasterStack.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Sensors]","category":"page"},{"location":"#RemoteSensingToolbox.Sensors.AbstractSensor","page":"Home","title":"RemoteSensingToolbox.Sensors.AbstractSensor","text":"The supertype of all sensor types. \n\nSubtypes should wrap a RasterStack under the field 'stack' and implement the following interface:\n\nblue(X::Sensor)\n\ngreen(X::Sensor)\n\nred(X::Sensor) \n\nnir(X::Sensor) \n\nswir1(X::Sensor)\n\nswir2(X::Sensor)\n\ndn2rs(::Type{<:AbstractSensor})\n\nBandSet(::Type{Landsat8})\n\nExample Implementation\n\nstruct Landsat8 <: AbstractSensor\n    stack::RasterStack\nend\n\nfunction BandSet(::Type{Landsat8})\n    bands = [:B1, :B2, :B3, :B4, :B5, :B6, :B7]\n    wavelengths = [440, 480, 560, 655, 865, 1610, 2200]\n    return BandSet(bands, wavelengths)\nend\n    \nblue(X::Landsat8) = X[:B2]\n\ngreen(X::Landsat8) = X[:B3]\n\nred(X::Landsat8) = X[:B4]\n\nnir(X::Landsat8) = X[:B5]\n\nswir1(X::Landsat8) = X[:B6]\n\nswir2(X::Landsat8) = X[:B7]\n\ndn2rs(::Type{Landsat8}) = (scale=0.0000275, offset=-0.2)\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Sensors.BandSet","page":"Home","title":"RemoteSensingToolbox.Sensors.BandSet","text":"A struct for storing the band names and associated wavelengths of a particular sensor.\n\nIt is expected that instances of AbstractSensor implement a BandSet constructor.\n\nThe central wavelength for a given band can be recovered by calling the BandSet.\n\nExample\n\njulia> bandset = BandSet(Sentinel2A);\njulia> bandset(:B8A)\n842.0\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Sensors.DESIS","page":"Home","title":"RemoteSensingToolbox.Sensors.DESIS","text":"stack::Rasters.RasterStack\n\nImplements the AbstractSensor interface for DESIS.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Sensors.Landsat7","page":"Home","title":"RemoteSensingToolbox.Sensors.Landsat7","text":"stack::Rasters.RasterStack\n\nImplements the AbstractSensor interface for Landsat 7.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Sensors.Landsat8","page":"Home","title":"RemoteSensingToolbox.Sensors.Landsat8","text":"stack::Rasters.RasterStack\n\nImplements the AbstractSensor interface for Landsat 8.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Sensors.Sentinel2A","page":"Home","title":"RemoteSensingToolbox.Sensors.Sentinel2A","text":"stack::Rasters.RasterStack\n\nImplements the AbstractSensor interface for Sentinel-2A.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Sensors.asraster-Union{Tuple{T}, Tuple{Any, T}} where T<:AbstractSensor","page":"Home","title":"RemoteSensingToolbox.Sensors.asraster","text":"asraster(f, X::AbstractSensor)\n\nOperate on the AbstractSensor as if it was a regular Rasters.RasterStack.\n\nExample\n\nlandsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\")\nasraster(landsat) do stack\n    map(x -> x .* 0.0001f0, stack)\nend\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.blue-Tuple{AbstractSensor}","page":"Home","title":"RemoteSensingToolbox.Sensors.blue","text":"blue(X::AbstractSensor)\n\nReturn the blue band for the given sensor.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.dn2rs-Union{Tuple{Type{T}}, Tuple{T}} where T<:AbstractSensor","page":"Home","title":"RemoteSensingToolbox.Sensors.dn2rs","text":"dn2rs(::Type{<:AbstractSensor})\n\nReturn the scale and offset required to convert DN to reflectance for the given sensor type.\n\nExample\n\njulia> dn2rs(Landsat8)\n(scale = 2.75e-5, offset = -0.2)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.green-Tuple{AbstractSensor}","page":"Home","title":"RemoteSensingToolbox.Sensors.green","text":"green(X::AbstractSensor)\n\nReturn the green band for the given sensor.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.nir-Tuple{AbstractSensor}","page":"Home","title":"RemoteSensingToolbox.Sensors.nir","text":"nir(X::AbstractSensor)\n\nReturn the nir band for the given sensor.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.red-Tuple{AbstractSensor}","page":"Home","title":"RemoteSensingToolbox.Sensors.red","text":"red(X::AbstractSensor)\n\nReturn the red band for the given sensor.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.swir1-Tuple{AbstractSensor}","page":"Home","title":"RemoteSensingToolbox.Sensors.swir1","text":"swir1(X::AbstractSensor)\n\nReturn the swir1 band for the given sensor.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Sensors.swir2-Tuple{AbstractSensor}","page":"Home","title":"RemoteSensingToolbox.Sensors.swir2","text":"swir2(X::AbstractSensor)\n\nReturn the swir2 band for the given sensor.\n\n\n\n\n\n","category":"method"},{"location":"#Visualization","page":"Home","title":"Visualization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"visualization.jl\"]","category":"page"},{"location":"#RemoteSensingToolbox.Agriculture","page":"Home","title":"RemoteSensingToolbox.Agriculture","text":"Agriculture band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.ColorInfrared","page":"Home","title":"RemoteSensingToolbox.ColorInfrared","text":"Color infrared band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.Geology","page":"Home","title":"RemoteSensingToolbox.Geology","text":"Geology band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.SWIR","page":"Home","title":"RemoteSensingToolbox.SWIR","text":"SWIR band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.TrueColor","page":"Home","title":"RemoteSensingToolbox.TrueColor","text":"True color band composite.\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.visualize-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.visualize","text":"visualize(r::AbstractRaster, g::AbstractRaster, b::AbstractRaster; lower=0.02, upper=0.98)\nvisualize(g::AbstractRaster; lower=0.02, upper=0.98)\nvisualize(img::AbstractSensor, ::Type{TrueColor}; lower=0.02, upper=0.98)\nvisualize(img::AbstractSensor, ::Type{ColorInfrared}; lower=0.02, upper=0.98)\nvisualize(img::AbstractSensor, ::Type{SWIR}; lower=0.02, upper=0.98)\nvisualize(img::AbstractSensor, ::Type{Agriculture}; lower=0.02, upper=0.98)\nvisualize(img::AbstractSensor, ::Type{Geology}; lower=0.02, upper=0.98)\n\nVisualize a remotely sensed image by applying a histogram stretch. Returns either an RGB or grayscale image compatible with the Images.jl ecosystem.\n\nA number of band combinations are supported for types implementing the AbstractSensor interface.\n\nExample 1\n\nlandsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\")\nimg = visualize(red(landsat), green(landsat), blue(landsat))\nsave(\"truecolor.png\", img)\n\nExample 2\n\nlandsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\")\nimg = visualize(landsat, TrueColor)\nsave(\"truecolor.png\", img)\n\n\n\n\n\n","category":"method"},{"location":"#Preprocessing","page":"Home","title":"Preprocessing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Preprocessing]","category":"page"},{"location":"#RemoteSensingToolbox.Preprocessing.create_tiles-Tuple{Any, Tuple{Int64, Int64}}","page":"Home","title":"RemoteSensingToolbox.Preprocessing.create_tiles","text":"create_tiles(raster, tile::Tuple{Int,Int}; stride=tile)\n\nSlice the given raster into tiles with size tile.\n\nParameters\n\nraster: The raster to be cut into tiles.\ntile: The size of the generated tiles in terms of width x height.\nstride: The distance between the top-left corner of each tile. Is equal to tile by default, which produces non-overlapping tiles.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Preprocessing.dn_to_reflectance-Tuple{T} where T<:AbstractSensor","page":"Home","title":"RemoteSensingToolbox.Preprocessing.dn_to_reflectance","text":"dn_to_reflectance(X::AbstractSensor)\ndn_to_reflectance(X::AbstractRasterStack, scale, offset)\n\nTransform the raster from Digital Numbers (DN) to reflectance.\n\nParameters\n\nX: The RasterStack or AbstractSensor to be converted to reflectance.\nscale: The scaling factor used to convert DN to reflectance. Inferred for AbstractSensor types.\noffset: The offset used to convert DN to reflectance. Inferred for AbstractSensor types.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Preprocessing.landsat_qa-Tuple{String}","page":"Home","title":"RemoteSensingToolbox.Preprocessing.landsat_qa","text":"landsat_qa(qa::String)\n\nRead and decode a landsat quality assurance (QA) raster. Decodes each bit into its own RasterStack layer.\n\nExample\n\njulia> qa = landsat_qa(\"LC08_L2SP_043024_20200802_20200914_02_T1_QA_PIXEL.TIF\")\nRasterStack with dimensions: \n  X Projected{Float64} LinRange{Float64}(493785.0, 728385.0, 7821) ForwardOrdered Regular Points crs: WellKnownText,\n  Y Projected{Float64} LinRange{Float64}(5.84638e6, 5.60878e6, 7921) ReverseOrdered Regular Points crs: WellKnownText\nand 8 layers:\n  :fill          UInt8 dims: X, Y (7821×7921)\n  :dilated_cloud UInt8 dims: X, Y (7821×7921)\n  :cirrus        UInt8 dims: X, Y (7821×7921)\n  :cloud         UInt8 dims: X, Y (7821×7921)\n  :cloud_shadow  UInt8 dims: X, Y (7821×7921)\n  :snow          UInt8 dims: X, Y (7821×7921)\n  :clear         UInt8 dims: X, Y (7821×7921)\n  :water         UInt8 dims: X, Y (7821×7921)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Preprocessing.mask_pixels-Tuple{Rasters.AbstractRaster, Any}","page":"Home","title":"RemoteSensingToolbox.Preprocessing.mask_pixels","text":"mask_pixels(raster, mask; invert_mask=false)\n\nDrop pixels from a raster according to a given mask. The mask and raster must have the same extent and size.\n\nParameters\n\nraster: The raster to be masked.\nmask: A mask defining which pixels we want to drop. By default, we drop pixels corresponding to mask values of 1.\ninvert_mask: Treat mask values of 1 as 0 and vice-versa.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Preprocessing.tocube-Tuple{Rasters.RasterStack}","page":"Home","title":"RemoteSensingToolbox.Preprocessing.tocube","text":"tocube(rs::RasterStack; layers=names(rs))\ntocube(rs::AbstractSensor; layers=names(rs))\n\nTransform the multi-layer RasterStack to a multi-band raster.\n\nParameters\n\nX: The RasterStack or AbstractSensor to be transformed into a multi-band raster.\nlayers: The layers to include in the new raster.\n\nExample\n\njulia> landsat = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1\");\njulia> tocube(landsat)\n7821×7921×7 Raster{Float32,3} B1 with dimensions: \n  X Projected{Float64} LinRange{Float64}(493785.0, 728385.0, 7821) ForwardOrdered Regular Points crs: WellKnownText,\n  Y Projected{Float64} LinRange{Float64}(5.84638e6, 5.60878e6, 7921) ReverseOrdered Regular Points crs: WellKnownText,\n  Band Categorical{Int64} 1:7 ForwardOrdered\nextent: Extent(X = (493785.0, 728385.0), Y = (5.608785e6, 5.846385e6), Band = (1, 7))\nmissingval: 0.0f0\ncrs: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]\nparent:\n[:, :, 1]\n           5.84638e6  5.84636e6  5.84632e6  5.8463e6  5.84626e6  …  5.60894e6  5.6089e6  5.60888e6  5.60884e6  5.60882e6  5.60878e6\n 493785.0  0.0        0.0        0.0        0.0       0.0           0.0        0.0       0.0        0.0        0.0        0.0\n      ⋮                                               ⋮          ⋱                                             ⋮          \n 728355.0  0.0        0.0        0.0        0.0       0.0           0.0        0.0       0.0        0.0        0.0        0.0\n 728385.0  0.0        0.0        0.0        0.0       0.0           0.0        0.0       0.0        0.0        0.0        0.0\n[and 6 more slices...]\n\n\n\n\n\n","category":"method"},{"location":"#Land-Cover-Indices","page":"Home","title":"Land Cover Indices","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Algorithms]\nPages = [\"Algorithms/indices.jl\"]","category":"page"},{"location":"#RemoteSensingToolbox.Algorithms.mndwi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.mndwi","text":"mndwi(green::AbstractRaster, swir::AbstractRaster)\nmndwi(sensor::AbstractSensor)\n\nCompute the Modified Normalised Difference Water Index (Xu 2006).\n\nMNDWI = (green - swir) / (green + swir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Algorithms.nbri-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.nbri","text":"nbri(nir::AbstractRaster, swir2::AbstractRaster)\nnbri(sensor::AbstractSensor)\n\nCompute the Normalized Burn Ratio Index.\n\nNBRI is used to emphasize burned areas.\n\nNBRI = (nir - swir2) / (nir + swir2)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Algorithms.ndbi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.ndbi","text":"ndbi(swir1::AbstractRaster, nir::AbstractRaster)\nndbi(sensor::AbstractSensor)\n\nCompute the The Normalized Difference Built-up Index\n\nNDBI is used to emphasize urban and built-up areas.\n\nNDBI = (swir1 - nir) / (swir1 + nir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Algorithms.ndmi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.ndmi","text":"ndmi(nir::AbstractRaster, swir1::AbstractRaster)\nndmi(sensor::AbstractSensor)\n\nCompute the Normalized Difference Moisture Index.\n\nNDMI is sensitive to the moisture levels in vegetation. It is used to monitor droughts and fuel levels in fire-prone areas.\n\nNDMI = (nir - swir1) / (nir + swir1)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Algorithms.ndvi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.ndvi","text":"ndvi(nir::AbstractRaster, red::AbstractRaster)\nndvi(sensor::AbstractSensor)\n\nCompute the Normalized Difference Vegetation Index.\n\nNDVI = (nir - red) / (nir + red)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Algorithms.ndwi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.ndwi","text":"ndwi(green::AbstractRaster, nir::AbstractRaster)\nndwi(sensor::AbstractSensor)\n\nCompute the Normalized Difference Water Index (McFeeters 1996).\n\nNDWI = (green - nir) / (green + nir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Algorithms.savi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.Algorithms.savi","text":"savi(nir::AbstractRaster, red::AbstractRaster; L=0.33)\nsavi(sensor::AbstractSensor; L=0.33)\n\nCompute the Soil Adjusted Vegetation Index (Huete 1988).\n\nSAVI is a vegetation index which attempts to minimize soil brightness influences by introducing a soil-brightness correction factor (L).\n\nL represents the amount of green vegetation cover, which is set to 0.33 by default.\n\nSAVI = ((nir - red) / (nir + red + L)) * (1 + L)\n\n\n\n\n\n","category":"method"},{"location":"#Spectral-Analysis","page":"Home","title":"Spectral Analysis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox.Spectral]","category":"page"},{"location":"#RemoteSensingToolbox.Spectral.extract_signatures-Tuple{Rasters.RasterStack, DataFrames.DataFrame, Symbol}","page":"Home","title":"RemoteSensingToolbox.Spectral.extract_signatures","text":"extract_signatures(rs::AbstractSensor, shp::DataFrame, label::Symbol)\nextract_signatures(rs::RasterStack, shp::DataFrame, label::Symbol)\n\nExtract signatures from the given RasterStack or AbstractSensor within regions specified by a given shapefile.\n\nParameters\n\nrs: The RasterStack or AbstractSensor from which to extract spectral signatures.\nshp: A shapefile stored as a DataFrame with a :geometry column storing a GeoInterface.jl compatible geometry and a label column indicating the land cover type.\nlabel: The column in shp in which the land cover class is stored.\n\nReturns\n\nA DataFrame consisting of rows for each extracted signature and columns storing the respective bands and land cover type.\n\nExample\n\njulia> landsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\") |> dn_to_reflectance;\n\njulia> shp = Shapefile.Table(\"data/landcover/landcover.shp\") |> DataFrame;\n\njulia> extract_signatures(landsat, shp, :cover)\n3195×8 DataFrame\n  Row │ B1          B2         B3         B4         B5        B6         B7         label      \n      │ Float64     Float64    Float64    Float64    Float64   Float64    Float64    String     \n──────┼─────────────────────────────────────────────────────────────────────────────────────────\n    1 │  0.05102    0.0891075  0.156317   0.198558   0.482055  0.267197   0.139103   hail scar\n    2 │  0.054815   0.09238    0.16333    0.207742   0.481203  0.270415   0.140973   hail scar\n    3 │  0.0561625  0.0942225  0.16564    0.208787   0.477875  0.273082   0.14353    hail scar\n    4 │  0.057015   0.0941125  0.16146    0.20425    0.47991   0.271267   0.141715   hail scar\n    5 │  0.044695   0.0839375  0.152852   0.193525   0.465198  0.258012   0.133217   hail scar\n  ⋮   │     ⋮           ⋮          ⋮          ⋮         ⋮          ⋮          ⋮          ⋮\n 3192 │ -0.0024675  0.011475   0.0757425  0.0416975  0.540658  0.0856975  0.035785   vegetation\n 3193 │ -0.001945   0.0115575  0.0766225  0.0419725  0.535488  0.08567    0.036005   vegetation\n 3194 │ -0.0023025  0.012135   0.0773925  0.0427975  0.523745  0.08556    0.0364175  vegetation\n 3195 │ -0.0019725  0.0119425  0.0767875  0.04211    0.523745  0.085065   0.0360325  vegetation\n                                                                               3186 rows omitted\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Spectral.plot_signatures!-Tuple{Makie.Axis, Rasters.RasterStack, DataFrames.DataFrame, BandSet, Symbol}","page":"Home","title":"RemoteSensingToolbox.Spectral.plot_signatures!","text":"plot_signatures!(ax::Axis, rs::AbstractSensor, shp::DataFrame, label::Symbol; colors=wong_colors())\nplot_signatures!(ax::Axis, rs::RasterStack, shp::DataFrame, bandset::BandSet, label::Symbol; colors=wong_colors())\n\nPlot spectral signatures for each land cover type specified in a given shapefile by mutating a Makie.Axis object.\n\nParameters\n\nax: The Makie.Axis into which we want to draw our plot.\nrs: The RasterStack or AbstractSensor from which to extract spectral signatures.\nshp: A shapefile stored as a DataFrame with a :geometry column storing a GeoInterface.jl compatible geometry and a label column indicating the land cover type.\nbandset: The BandSet for the provided sensor specifying the available bands and associated wavelengths in nm. Inferred for AbstractSensor.\nlabel: The column in shp in which the land cover class is stored.\ncolors: The color scheme used by the plot.\n\nExample\n\n# Read Landsat And Convert DNs To Reflectance\nlandsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\") |> dn_to_reflectance\n\n# Load Shapefile\nshp = Shapefile.Table(\"data/landcover/landcover.shp\") |> DataFrame\n\n# Create Axes\nfig = Figure();\nax1 = Axis(fig[1,1]);\nax2 = Axis(fig[2,1]);\n\n# Plot Signatures\nplot_signatures!(ax1, landsat, shp, :C_name; colors=cgrad(:tab10));\nplot_signatures!(ax2, landsat, shp, :MC_name; colors=cgrad(:tab10));\n\n# Add Legend\nLegend(fig[1,2], ax1);\nLegend(fig[2,2], ax2);\n\n# Save Figure\nsave(\"landsat_signatures.png\", fig)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.Spectral.plot_signatures-Tuple{Rasters.RasterStack, DataFrames.DataFrame, BandSet, Symbol}","page":"Home","title":"RemoteSensingToolbox.Spectral.plot_signatures","text":"plot_signatures(rs::AbstractSensor, shp::DataFrame, label::Symbol; colors=wong_colors())\nplot_signatures(rs::RasterStack, shp::DataFrame, bandset::BandSet, label::Symbol; colors=wong_colors())\n\nPlot spectral signatures for each land cover type specified in a given shapefile.\n\nParameters\n\nrs: The RasterStack or AbstractSensor from which to extract spectral signatures.\nshp: A shapefile stored as a DataFrame with a :geometry column storing a GeoInterface.jl compatible geometry and a label column indicating the land cover type.\nbandset: The BandSet for the provided sensor specifying the available bands and associated wavelengths in nm. Inferred for AbstractSensor.\nlabel: The column in shp in which the land cover class is stored.\ncolors: The color scheme used by the plot.\n\nExample\n\n# Read Landsat And Convert DNs To Reflectance\nlandsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\") |> dn_to_reflectance\n\n# Load Shapefile\nshp = Shapefile.Table(\"data/landcover/landcover.shp\") |> DataFrame\n\n# Plot Signatures\nplot_signatures(landsat, shp, :C_name; colors=cgrad(:tab10))\n\n\n\n\n\n","category":"method"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"visualization_example/#Visualization-Example","page":"Visualization","title":"Visualization Example","text":"","category":"section"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"RemoteSensingToolbox provides a number of utilities for visualizing remote sensing imagery. First, lets load the imagery we want to visualize. We're working with Landsat 8 imagery, so we'll use the Landsat8 constructor to wrap our rasters in the appropriate context. Landsat8 is an instance of AbstractSensor, which allow many methods within RemoteSensingToolbox to infer sensor-specific information by exploiting Julia's multiple dispatch system. The Landsat8 constructor expects a directory storing Landsat 8 raster files with names conforming to the standard specification. If this is not the case, you may construct a Rasters.RasterStack manually and pass it to the constructor instead.","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"using RemoteSensingToolbox, Images, Rasters\n\nlandsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\")","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"Now let's visualize our data to see what we're working with. This is where the power of AbstractSensor can first be demonstrated. To view a true color composite of the data, we need to know the bands corresponding to red, green, and blue. However, it would be tedious to memorize and manually specify this information whenever we want to call a method which relies on a specific combination of bands. Fortunately, all AbstractSensor subtypes know this information implicitly, so all we need to do is pass TrueColor into the visualize method to automatically extract the appropriate bands.","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"visualize(landsat, TrueColor; upper=0.90)","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"(Image: )","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"You may have noticed that we also provided an additional argument upper to the visualize method. This parameter controls the upper quantile to be used when performing histogram stretching to make the imagery more interpretable to humans. This parameter is set to 0.98 by default, but because our scene contains bright clouds, we need to lower this threshold to prevent the image from appearing too dark. Let's try again with another band combination. The Agriculture band comination is commonly used to distinguish regions with healthy vegetation, which appear as various shades of green.","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"visualize(landsat, Agriculture; upper=0.90)","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"(Image: )","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"We can also view a mosaic of all the bands in our image by calling Images.mosaicview.","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"mosaicview(landsat; upper=0.90, rowmajor=true, ncol=4)","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"(Image: )","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"We'll finish this example by demonstrating how easy it is to compute land cover indices with any AbstractSensor subtype. The Modified Normalized Difference Water Index (MNDWI) is an especially popular index, which is used to help distinguish water from land. Here, we visualize both the true color representation and the corresponding MNDWI index.","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"# AbstractSensors are compatible with all view and index operations supported by Rasters.jl \npatch = @view landsat[X(5800:6800), Y(2200:3200)]\n\n# Visualize a true color representation next to the calculated MNDWI\ntrue_color = visualize(patch, TrueColor; upper=0.998)\nindex = visualize(mndwi(patch))\nmosaicview(true_color, index; npad=5, fillvalue=0.0, ncol=2)","category":"page"},{"location":"visualization_example/","page":"Visualization","title":"Visualization","text":"(Image: )","category":"page"}]
}
