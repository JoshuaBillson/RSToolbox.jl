var documenterSearchIndex = {"docs":
[{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"quickstart/#Quick-Start","page":"Quick Start","title":"Quick Start","text":"","category":"section"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"RemoteSensingToolbox is a pure Julia package which provides a number of utilities for reading, visualizing, and processing remotely sensed imagery. When working with such data, the user is often faced with the need to adapt their approach according to the type of sensor that produced it. For example, decoding digital numbers into radiance,  reflectance, or temperature requires knowledge about the encoding scheme used by the satellite product in question. The address these issues, we provide several AbstractSatellite types, which encode various parameters at the type level. ","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Typically, the first step in a workflow is to read the desired layers from disk. To do so, we first need to place our product within the appropriate context; in this case Landsat8. With this done, we can load whichever layers we desire simply by asking for them by name. A complete list of all available layers can be acquired by calling layers(Landsat8). To load a single layer, we typically use a Raster, while a RasterStack is used  when loading multiple layers at once. By default, RasterStack will read all of the spectral layers when no layers are specified. We can also specify the keyword lazy=true to avoid loading everything into memory. When  doing so, the raster(s) will not be retrieved from disk until explicitly indexed or read.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"using RemoteSensingToolbox, Rasters, ArchGDAL, DataDeps, Fetch\n\n# DataDeps Settings\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nENV[\"DATADEPS_LOAD_PATH\"] = joinpath(pwd(), \"data\")\n\n# Fetch Landsat Scene from Google Drive\nregister(\n    DataDep(\n        \"LC08_L2SP_043024_20200802_20200914_02_T1\", \n        \"Landsat 8 Test Data\",\n        \"https://drive.google.com/file/d/1S5H_oyWZZInOzJK4glBCr6LgXSADzhOV/view?usp=sharing\", \n        \"2ce24abc359d30320213237d78101d193cdb8433ce21d1f7e9f08ca140cf5785\", \n        fetch_method=gdownload, \n        post_fetch_method=unpack\n    )\n)\n\n# Read Landsat Bands\nsrc = Landsat8(datadep\"LC08_L2SP_043024_20200802_20200914_02_T1\")\nstack = RasterStack(src, lazy=true)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Now let's visualize our data to see what we're working with. The true_color method displays the red, green, and blue bands to provide an image that is familiar to the human eye. In most other frameworks, we would have to specify each of these bands individually, which in turn requires knowledge about the sensor in question. However, because we have placed our scene within a Landsat8 context, true_color is smart enough to figure this out on its own. As an alternative, we could have also called true_color(Landsat8, stack; upper=0.90), which requires passing in the sensor type as the first agument and a stack containing the relevant bands as the second. Many other methods  in RemoteSensingToolbox follow this same pattern.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"true_color(src; upper=0.90)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"You may have noticed that we provided an additional argument upper to true_color. This parameter controls the  upper quantile to be used during the histogram adjustment. This parameter is set to 0.98 by default, but because  our scene contains a significant number of bright clouds, we need to lower it to prevent the image from appearing  too dark. We can remove these clouds by loading the :clouds and :cloud_shadow layers from the provided scene and then calling apply_masks.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"# Mask Clouds\ncloud_mask = Raster(src, :clouds)\nshadow_mask = Raster(src, :cloud_shadow)\nmasked = apply_masks(stack, cloud_mask, shadow_mask)\n\n# Visualize in True Color\ntrue_color(Landsat8, masked)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"Now let's try to visualize some other band combinations. The Agriculture band comination is commonly used to  emphasize regions with healthy vegetation, which appear as various shades of green.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"agriculture(src; upper=0.90)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"We'll finish this example by computing a few different land cover indices. Each index expects two bands as input,  such as green and swir (MNDWI), red and nir (NDVI), or nir and swir (NDMI). As with visualization, we do not need to specify these bands manually so long as the type of sensor is known. In general, each index has  three forms: one that requires only a single AbstractSatellite instance, a second that expects both the type  of satellite and a RasterStack, and a third which expects a Raster for each band.","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"# Extract Region of Interest\nroi = @view masked[X(5800:6800), Y(2200:3200)]\n\n# Calculate Indices\nindices = map(visualize, [mndwi(Landsat8, roi), ndvi(Landsat8, roi), ndmi(Landsat8, roi)])\n\n# Visualize\ntc = true_color(Landsat8, roi; upper=0.998)\nmosaic = mosaicview([tc, indices...]; npad=10, fillvalue=0.0, ncol=2, rowmajor=true)","category":"page"},{"location":"quickstart/","page":"Quick Start","title":"Quick Start","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"spectral_example/#Spectral-Analysis","page":"Spectral Analysis","title":"Spectral Analysis","text":"","category":"section"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Land cover classification is a common application of remotely sensed imagery. Such a task involves  assigning a discrete label to each pixel in an image denoting the type of land contained within it. For example, we may wish to classify each pixel as either water or land. This is typically  accomplished by observing the unique spectral signatures produced by each material. RemoteSensingToolbox provides a number of methods for both extracting and visualizing signatures from a labelled image.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Our first step is to read the relevant bands from disk and convert the DNs (Digital Numbers) to  reflectance. Reflectance is a standardized unit of measurement defined over the interval [0, 1], which denotes the fraction of light reflected by the observed surface. A reflectance of 0.0 indicates that no light was reflected at all, whereas a reflectance of 1.0 tells us that 100% was reflected.  Fortunately, each AbstractSatellite contains the necessary information for this conversion.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"using RemoteSensingToolbox, Rasters, ArchGDAL, Statistics, DataFrames, Shapefile\n\n# Read Landsat, Sentinel, and DESIS Bands\nlandsat_src = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1\")\nsentinel_src = Sentinel2{60}(\"data/S2B_MSIL2A_20200804T183919_N0214_R070_T11UPT_20200804T230343\")\ndesis_src = DESIS(\"data/DESIS-HSI-L2A-DT0485529167_001-20220712T223540-V0220\")\nlandsat = RasterStack(landsat_src, lazy=true)\nsentinel = RasterStack(sentinel_src, lazy=true)\ndesis = Raster(desis_src, :Bands, lazy=true)\n\n# Convert DNs to Surface Reflectance\nlandsat_sr = decode(Landsat8, landsat)\nsentinel_sr = decode(Sentinel2{60}, sentinel)\ndesis_sr = decode(DESIS, desis)","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Once we have our imagery, we need to acquire some labelled regions from which to extract the spectral signatures.  This is typically accomplished with a shapefile consisting of polygons labelled with each type of land cover.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"shp = Shapefile.Table(\"data/landcover/landcover.shp\") |> DataFrame","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Examining the shapefile gives us some insight into how its contents are structured. As we can see, the regions of interest are stored as Polygon objects under the :geometry column, while land cover labels are under both :MC_name and :C_name. In this case, :MC_name defines the macro class while :C_name defines the specific class. For example, both \"Trees\" and \"Vegetation\" belong to the \"Vegetation\" macro class.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"8×7 DataFrame\n Row │ geometry            fid      MC_ID  MC_name     C_ID   C_name      SCP_UID                   \n     │ Polygon             Missing  Int64  String      Int64  String      String                    \n─────┼──────────────────────────────────────────────────────────────────────────────────────────────\n   1 │ Polygon(38 Points)  missing      1  Built Up        1  Built Up    20230527_122212594060_314\n   2 │ Polygon(31 Points)  missing      1  Built Up        2  Road        20230527_122301732906_304\n   3 │ Polygon(57 Points)  missing      2  Vegetation      4  Trees       20230527_123221462871_572\n   4 │ Polygon(5 Points)   missing      3  Bare Earth      5  Hail Scar   20230527_123631491671_937\n   5 │ Polygon(7 Points)   missing      3  Bare Earth      6  Bare Earth  20230527_123727873290_779\n   6 │ Polygon(7 Points)   missing      4  Water           7  Lake        20230527_123931189139_867\n   7 │ Polygon(5 Points)   missing      3  Bare Earth      6  Bare Earth  20230527_125120033074_286\n   8 │ Polygon(5 Points)   missing      2  Vegetation      3  Vegetation  20230527_122832068862_308","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"We can call extract_signatures to retrieve the spectral signatures located within each polygon along with their associated labels. An optional aggregation method can be supplied as the first argument, which will be used to summarize signatures belonging to the same label. Some common examples are mean, median, maximum,  and minimum. If no method is provided, extract_signatures will return all signatures and their labels.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"sigs = extract_signatures(mean, landsat_sr, shp, :MC_name) |> DataFrame","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"4×8 DataFrame\n Row │ label       B1          B2          B3         B4          B5        B6          B7         \n     │ String      Float32     Float32     Float32    Float32     Float32   Float32     Float32    \n─────┼─────────────────────────────────────────────────────────────────────────────────────────────\n   1 │ Bare Earth  0.0566671   0.0871629   0.145427   0.185996    0.401831  0.317775    0.184228\n   2 │ Built Up    0.0506521   0.0679052   0.113027   0.120046    0.254274  0.236384    0.18103\n   3 │ Water       0.00137886  0.00423271  0.0135606  0.00652965  0.031825  0.00709321  0.00381732\n   4 │ Vegetation  0.00699952  0.0166328   0.0716218  0.0422207   0.462393  0.10416     0.0438761","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"While extract_signatures can be a good first step for further analysis or training classification models, we are  also often interested in visualizing the signatures associated with each land cover type. To do so, we can import CairoMakie, which is extended by RemoteSensingToolbox to provide signature plotting. In order to display the appropriate wavelength for each band, plot_signatures expects either a vector of band-wavelength pairs or an AbstractSatellite type as the first argument.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"import CairoMakie\n\nplot_signatures(Landsat8, landsat_sigs)","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"To override the default color scheme, we can provide an optional colors argument. Refer to  Colors.jl for a complete list of all named colors.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"colors = [:saddlebrown, :orange, :navy, :green]\nfig = plot_signatures(Landsat8, landsat_sigs, colors=colors)","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"Sometimes we want to have more control over our plots than what is provided by plot_signatures. To accommodate this need, we provide the plot_signatures! method, which directly modifies a provided Makie.Axis object. In the following example, we will plot the same signatures produced by three different sensors, each of which passed over our study area within a period of four days.","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"# Create Figure\nfig = CairoMakie.Figure(resolution=(1000, 800))\n\n# Create Axes\nax1 = CairoMakie.Axis(fig[1,1], title=\"Landsat 8\", xticksvisible=false, xticklabelsvisible=false)\nax2 = CairoMakie.Axis(fig[2,1], title=\"Sentinel 2\", ylabel=\"Reflectance\", ylabelfont=:bold, xticksvisible=false, xticklabelsvisible=false)\nax3 = CairoMakie.Axis(fig[3,1], title=\"DESIS\", xlabel=\"Wavelength (nm)\", xlabelfont=:bold)\n\n# Plot Signatures\naxs = (ax1, ax2, ax3)\nsensors = (Landsat8, Sentinel2{60}, DESIS)\nrasters = (landsat_sr, sentinel_sr, desis_sr)\nfor (sensor, raster, ax) in zip(sensors, rasters, axs)\n    sigs = extract_signatures(mean, raster, shp, :MC_name)\n    plot_signatures!(ax, sensor, sigs; colors=colors)\n    CairoMakie.xlims!(ax, 400, 1000)\nend\n\n# Add Legend\nCairoMakie.Legend(fig[1:3,2], first(axs), \"Classification\")","category":"page"},{"location":"spectral_example/","page":"Spectral Analysis","title":"Spectral Analysis","text":"(Image: )","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"pansharpening/#Pansharpening","page":"Pansharpening","title":"Pansharpening","text":"","category":"section"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"Pansharpening is the process of merging a high-resolution panchromatic image with a lower resolution  multispectral image to produce a high-resolution color image. Typically, the panchromatic band covers  the wavelengths of several bands in the corresponding multispectral image. For example, the panchromatic  band in Landsat 8 corresponds to the same wavelengths as the RGB bands. Here we will demonstrate a fairly simple method, which involves replacing the value channel from an HSV representation of the color image  with the panchromatic band. As always, the first step is to read the necessary layers from disk.","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"using RemoteSensingToolbox, Rasters, ArchGDAL, Images, DataDeps, Fetch\n\n# DataDeps Settings\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nENV[\"DATADEPS_LOAD_PATH\"] = joinpath(pwd(), \"data\")\n\n# Fetch Landsat 8 Scene from Google Drive\nregister(\n    DataDep(\n        \"LC08_L1TP_043024_20200802_20200914_02_T1\", \n        \"\"\"Landast 8 Pansharpening Example\"\"\", \n        \"https://drive.google.com/file/d/107GjXFqmtKeNMLdOUreq3jl5wWGCpYro/view?usp=sharing\", \n        \"d6dc0c29e76db6f60ac665194ddd565cb808417250218f35f2f405a97064f297\", \n        fetch_method=gdownload, \n        post_fetch_method=unpack\n    )\n)\n\n# Read RGB and Panchromatic Bands\nsrc = Landsat8(datadep\"LC08_L1TP_043024_20200802_20200914_02_T1\")\nstack = RasterStack(src, [:red, :green, :blue], lazy=true)\npanchromatic = Raster(src, :panchromatic, lazy=true)","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"Next, we crop our data to a region of interest, resample our RGB bands to the same resolution as the panchromatic band, and visualize the results.","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"# Crop to Region of Interest\nroi = @view stack[X(6715:6914), Y(1500:1699)]\nroi_hr = Rasters.resample(roi, res=15)  # Resample RGB to 15m\nroi_pan = Rasters.crop(panchromatic, to=roi_hr)\n\n# Visualize RGB and Panchromatic Bands\nrgb = visualize(roi_hr...)\npan = visualize(roi_pan)\nimg = mosaicview(rgb, pan, npad=1, ncol=2, rowmajor=false, fillvalue=RGB(1.0,1.0,1.0))","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"(Image: )","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"As we can see, the panchromatic band provides double the spatial resolution of the RGB bands  (15m vs 30m), but contains only a single channel of color. Our goal is to combine them to  acquire a high-resolution RGB image. This can be done quite simply by first converting our RGB image  to the HSV color-space then replacing the value channel with the histogram-matched panchromatic band.","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"# Convert to HSV and Replace Value Band with Panchromatic\nhsv = HSV.(rgb)\nadjust_histogram!(pan, Matching(targetimg=channelview(hsv)[3,:,:]))\nchannelview(hsv)[3,:,:] .= gray.(pan)\nsharpened = RGB.(hsv)\n\n# Visualize\nimg = mosaicview(rgb, sharpened, npad=1, ncol=2, rowmajor=false, fillvalue=RGB(1.0,1.0,1.0))","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"(Image: )","category":"page"},{"location":"pansharpening/","page":"Pansharpening","title":"Pansharpening","text":"The side-by-side results show that replacing the value channel has indeed sharpened the image considerably. Moreover, the color of the original image has been largely preserved by the  transformation. A common alternative to the HSV method is to first perform a PCA transformation  along the spectral dimension, replace the first principal component with the panchromatic band,  then reverse the transformation to recover the sharpened image.","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"pca_example/#Principal-Component-Analysis","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"","category":"section"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"Remotely sensed imagery typically consists of anywhere from five to several hundred spectral bands. These bands are often highly correlated because they occupy similar spectral regions. ","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"PCA is used in remote sensing to:","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"Create a smaller dataset from multiple bands, while retaining as much of the original spectral information as possible. The new image will consist of several uncorrelated PC bands.\nReveal complex relationships among spectral features.\nDetermine which characteristics are prevalent in most of the bands, and those that are specific to only a few.","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"Our first step is to load and visualize our data.","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"using RemoteSensingToolbox, Rasters, ArchGDAL, DataDeps, Fetch\nusing Pipe: @pipe\n\n# DataDeps Settings\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nENV[\"DATADEPS_LOAD_PATH\"] = joinpath(pwd(), \"data\")\n\n# Fetch Sentinel 2 Scene from Google Drive\nregister(\n    DataDep(\n        \"S2B_MSIL2A_20200804T183919_N0214_R070_T11UPT_20200804T230343\", \n        \"\"\"Sentinel 2 Test Data\"\"\", \n        \"https://drive.google.com/file/d/1P7TSPf_GxYtyOYat3iIui1hbjvb7H6a0/view?usp=sharing\", \n        \"4135c6192a314e0d08d21cf44ca3cde0f34f1968854275e32656278ca163a3e0\", \n        fetch_method=gdownload, \n        post_fetch_method=unpack\n    )\n)\n\n# Read Sentinel 2 Bands at 60m Resolution\nsrc = Sentinel2{60}(datadep\"S2B_MSIL2A_20200804T183919_N0214_R070_T11UPT_20200804T230343\")\nsentinel = RasterStack(src; lazy=false)\n\n# Extract Region of Interest\nroi = @view sentinel[Rasters.X(900:1799), Rasters.Y(1:900)]\n\n# Visualize Original Image\ntrue_color(Sentinel2{60}, roi; upper=0.99)","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"(Image: )","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"Next, we'll fit a PCA transformation to our image. We can optionally specify a fraction of  pixels to use for computing the transformation statistics. Choosing a value less than one can greatly reduce the computation time at the expense of precision. However, for sufficiently large  images, a fraction of 0.1 provides near-identical results to those acquired from the complete data  set.","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"pca = fit_pca(sentinel; method=:cov, stats_fraction=0.1)","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"PCA(dimensions=11) \n\nProjection Matrix:\n11×11 Matrix{Float32}:\n -0.026   -0.2068   0.359    0.312   -0.0956  -0.4791  -0.2246   0.6115  -0.187   -0.1491   0.1007\n -0.0361  -0.2354   0.3739   0.1417  -0.0496  -0.1544  -0.384   -0.3905   0.3475   0.2424  -0.5269\n -0.0775  -0.2406   0.3554  -0.1492   0.0608   0.0574  -0.0611  -0.2325   0.4331  -0.2812   0.6754\n -0.0396  -0.3231   0.321   -0.0301  -0.048    0.4006  -0.1104  -0.1695  -0.6672   0.3335   0.1734\n -0.1194  -0.2914   0.2233  -0.3824   0.3988   0.3537   0.1552   0.388    0.0935  -0.2656  -0.4083\n -0.3925   0.0354   0.0791  -0.5716   0.1024  -0.5641   0.2124  -0.0647  -0.1093   0.3454   0.0492\n -0.4949   0.1513   0.0179  -0.1063  -0.4124   0.0177  -0.1552  -0.2315  -0.2583  -0.6104  -0.1825\n -0.5216   0.1354  -0.1415  -0.0112  -0.2273   0.3424  -0.332    0.3901   0.3023   0.3891   0.1241\n -0.5257   0.084    0.0977   0.6027   0.4321   0.0232   0.3684  -0.1417  -0.0191   0.0176   0.0145\n -0.155   -0.549   -0.63     0.0249   0.3084  -0.1467  -0.3609  -0.0952  -0.0891  -0.098    0.0592\n -0.0695  -0.5511  -0.1381   0.1059  -0.5562   0.0012   0.5628   0.0345   0.1566   0.0705  -0.0666\n\nImportance of Components:\n  Cumulative Variance: 0.76  0.9679  0.989  0.9938  0.9968  0.9984  0.9991  0.9995  0.9998  ...  1.0\n  Explained Variance: 0.76  0.2078  0.0212  0.0047  0.0031  0.0016  0.0007  0.0004  0.0002  ...  0.0001","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"If we look at the cumulative variance, we see that we only need to retain the first three principal  components to account for 98.9% of the sample variance. Knowing this, we'll perform a forward rotation with forward_pca while specifying that we only want to keep the first three components.","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"# Perform a PCA Transformation while Retaining the First Three Components\ntransformed = forward_pca(pca, roi, 3)\n\n# Visualize Transformation\nr, g, b = (view(transformed, Rasters.Band(i)) for i in 1:3)\nvisualize(r, g, b; upper=0.99)","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"(Image: )","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"Each band in the transformed image corresponds to a linear combination of multiple bands from the  original image. Thus, the bands no longer relate to wavelengths of light, but instead capture  different characteristics of the underlying spectral signatures. In the above visualization, we  observe that water is highlighted in yellow, vegetation is green, and built-up land is magenta. ","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"We may also wish to reverse the transformation in order to recover an approximation of the original  image. This can be achieved with the inverse_pca method, which expects both a learned PCA rotation  and a previously transformed image as input. The return value is a Raster, which does not retain  any of the band names from the original image. To make our recovered image compatible with the  Sentinel2 type, we need to restore the layer names by passing the result to RasterStack.","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"# Reverse Transformation\nrecovered = RasterStack(inverse_pca(pca, transformed), layersfrom=Band, name=names(roi))\n\n# Visualize Recovered Image\ntrue_color(Sentinel2{60}, recovered; upper=0.99)","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"(Image: )","category":"page"},{"location":"pca_example/","page":"Principal Component Analysis","title":"Principal Component Analysis","text":"We can see that while the color of the recovered image is indeed similar to that of the original, there are some noticeable discrepancies. This is because some information was lost when we discarded the other eight principal components. Had we elected to retain all 11 components, we would find the  two images to be identical, minus some floating point error.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = RemoteSensingToolbox","category":"page"},{"location":"#RemoteSensingToolbox","page":"Home","title":"RemoteSensingToolbox","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RemoteSensingToolbox is a pure Julia package built  on top of Rasters.jl for reading, visualizing, and processing remotely  sensed imagery. Users may refer to the Tutorials section for examples on how to use this package.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install this package, first start the Julia REPL and then open the package manager by typing ]. You can then download RemoteSensingToolbox directly from the official Julia repository like so:","category":"page"},{"location":"","page":"Home","title":"Home","text":"(@v1.9) pkg> add RemoteSensingToolbox","category":"page"},{"location":"","page":"Home","title":"Home","text":"Once RemoteSensingToolbox has been installed, you can import it like any other Julia package. Please note that many features require you to also import the Rasters and ArchGDAL packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using RemoteSensingToolbox, Rasters, ArchGDAL","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is a work in progress, which means that new features are being added and existing features  are subject to change. To contribute, please create an issue on  GitHub or open a pull request. A summary of both  existing and planned features is provided below:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Feature Description Implemented\nReading and Writing Read layers from a scene and the write results to disk Yes\nVisualization Visualize images with various band composites Yes\nLand Cover Indices Calculate indices such as MNDWI and NDVI Yes\nQA and SCL Decoding Decode Quality Assurance and Scene Classification masks Yes\nPixel Masking Mask pixels to remove objects such as clouds or shadows Yes\nPCA Perform PCA analysis, transformation, and reconstruction Yes\nMNF Minimum Noise Fraction transformation and reconstruction Yes\nSignature Analysis Visualize spectral signatures for different land cover types Yes\nLand Cover Classification Exposes an MLJ interface for classifying land cover types No\nEndmember Extraction Extract spectral endmembers from an image No\nSpectral Unmixing Perform spectral unmixing under a given endmember library No","category":"page"},{"location":"#Rasters.jl","page":"Home","title":"Rasters.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RemoteSensingToolbox is intended to be used in conjunction with the wider Julia ecosystem and as such, seeks to avoid duplicating functinalities provided by other packages. As the majority of methods accept and return AbstractRaster or AbstractRasterStack objects, users should be able to call methods from Rasters.jl at any point in the processing pipeline. A summary of common functionalities offered by Rasters is provided below: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Method Description\nmosaic Join rasters covering different extents into a single array or file.\ncrop Shrink objects to specific dimension sizes or the extent of another object.\nextend Extend objects to specific dimension sizes or the extent of another object.\ntrim Trims areas of missing values for arrays and across stack layers.\nresample Resample data to a different size and projection, or snap to another object.\nmask Mask a raster by a polygon or the non-missing values of another Raster.\nreplace_missing Replace all missing values in a raster and update missingval.\nextract Extract raster values from points or geometries.\nzonal Calculate zonal statistics for a raster masked by geometries.","category":"page"},{"location":"#Satellites","page":"Home","title":"Satellites","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"When working with remotely sensed images, the user is often required to adapt their approach according to  the type of sensor that produced it. For example, decoding digital numbers into radiance, reflectance, or temperature requires knowledge about the encoding scheme used by the satellite in question. To address these issues, we provide the AbstractSatellite type, which encodes various sensor-specific parameters at the  type level for several popular platforms. This approach allows the end-user to write generic code that  automatically adapts to the sensor being used. For example, if we have bound the variable src to an instance  of Landsat8, then we can load a cloud mask from the included QA file by calling Raster(src, :clouds), or calculate the MNDWI index by calling mndwi(src).","category":"page"},{"location":"","page":"Home","title":"Home","text":"AbstractSatellite\nLandsat7\nLandsat8\nLandsat9\nSentinel2\nDESIS\nbands\nlayers\nwavelengths\nwavelength\nblue_band\ngreen_band\nred_band\nnir_band\nswir1_band\nswir2_band\ndn_scale\ndn_offset\ndecode\nencode\nSatelliteDataSources.metadata\nRasters.Raster\nRasters.RasterStack","category":"page"},{"location":"#SatelliteDataSources.AbstractSatellite","page":"Home","title":"SatelliteDataSources.AbstractSatellite","text":"The super-type of all satellites. \n\nSub-types must implement the AbstractSatellite interface.\n\n\n\n\n\n","category":"type"},{"location":"#SatelliteDataSources.Landsat7","page":"Home","title":"SatelliteDataSources.Landsat7","text":"Implements the AbstractSatellite interface for Landsat 7.\n\nSupported Bands: :B1, :B2, :B3, :B4, :B5, :B7, :thermal, :panchromatic\n\nSupported Colors: :blue, :green, :red, :nir, :swir1, :swir2\n\nSupported Masks: :dilated_clouds, :clouds, :cloud_shadow, :snow, :water\n\n\n\n\n\n","category":"type"},{"location":"#SatelliteDataSources.Landsat8","page":"Home","title":"SatelliteDataSources.Landsat8","text":"Implements the AbstractSatellite interface for Landsat 8.\n\nSupported Bands: :B1, :B2, :B3, :B4, :B5, :B6, :B7, :thermal1, :thermal2, :panchromatic\n\nSupported Colors: :blue, :green, :red, :nir, :swir1, :swir2\n\nSupported Masks: :dilated_clouds, :clouds, :cloud_shadow, :snow, :water\n\n\n\n\n\n","category":"type"},{"location":"#SatelliteDataSources.Landsat9","page":"Home","title":"SatelliteDataSources.Landsat9","text":"Implements the AbstractSatellite interface for Landsat 9.\n\nSupported Layers: :B1, :B2, :B3, :B4, :B5, :B6, :B7, :thermal1, :thermal2, :panchromatic\n\nSupported Colors: :blue, :green, :red, :nir, :swir1, :swir2\n\nSupported Masks: :dilated_clouds, :clouds, :cloud_shadow, :snow, :water\n\n\n\n\n\n","category":"type"},{"location":"#SatelliteDataSources.Sentinel2","page":"Home","title":"SatelliteDataSources.Sentinel2","text":"Implements the AbstractSatellite interface for Sentinel 2.\n\nThe user must specify a resolution of 10, 20, or 60 meters.\n\nSupported Bands (10m): :B02, :B03, :B04, :B08\n\nSupported Bands (20m): :B02, :B03, :B04, :B05, :B06, :B07, :B8A, :B11, :B12\n\nSupported Bands (60m): :B01, :B02, :B03, :B04, :B05, :B06, :B07, :B8A, :B09, :B11, :B12\n\nSupported Colors (10m): :blue, :green, :red, :nir  \n\nSupported Colors (20m and 60m): :blue, :green, :red, :nir, :swir1, :swir2  \n\nSupported Masks (20m and 60m): :cloud_shadow, :clouds_med, :clouds_high, :cirrus, :vegetation, :soil, :water, :snow  \n\n\n\n\n\n","category":"type"},{"location":"#SatelliteDataSources.DESIS","page":"Home","title":"SatelliteDataSources.DESIS","text":"Implements the AbstractSatellite interface for DESIS.\n\nSupported Bands: :Bands, :Band_30, :Band_65, :Band_100, :Band_175\n\nSupported Colors: :blue, :green, :red, :nir\n\nSupported Masks: :clouds, :shadow, :haze, :snow, :land, :water\n\n\n\n\n\n","category":"type"},{"location":"#SatelliteDataSources.bands","page":"Home","title":"SatelliteDataSources.bands","text":"bands(::Type{AbstractSatellite})\n\nReturn the band names in order from shortest to longest wavelength.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.layers","page":"Home","title":"SatelliteDataSources.layers","text":"layers(::Type{AbstractSatellite})\nlayers(x::AbstractSatellite)\n\nReturn the names of all layers available for the given sensor.\n\nExample\n\n# Get all Available Layers for Landsat 8\nlandsat_layers = layers(Landsat8)\n\n# Get all Available Layers for a Specific Scene\nsrc = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1\")\navailable_layers = layers(src)\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.wavelengths","page":"Home","title":"SatelliteDataSources.wavelengths","text":"wavelengths(::Type{AbstractSatellite})\n\nReturn the central wavelengths for all bands in order from shortest to longest.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.wavelength","page":"Home","title":"SatelliteDataSources.wavelength","text":"wavelength(::Type{AbstractSatellite}, band::Symbol)\n\nReturn the central wavelength for the corresponding band.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.blue_band","page":"Home","title":"SatelliteDataSources.blue_band","text":"blue_band(::Type{AbstractSatellite})\n\nReturn the blue band for the given sensor.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.green_band","page":"Home","title":"SatelliteDataSources.green_band","text":"green_band(::Type{AbstractSatellite})\n\nReturn the green band for the given sensor.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.red_band","page":"Home","title":"SatelliteDataSources.red_band","text":"red_band(::Type{AbstractSatellite})\n\nReturn the red band for the given sensor.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.nir_band","page":"Home","title":"SatelliteDataSources.nir_band","text":"nir_band(::Type{AbstractSatellite})\n\nReturn the nir band for the given sensor.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.swir1_band","page":"Home","title":"SatelliteDataSources.swir1_band","text":"swir1_band(::Type{AbstractSatellite})\n\nReturn the swir1 band for the given sensor.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.swir2_band","page":"Home","title":"SatelliteDataSources.swir2_band","text":"swir2_band(::Type{AbstractSatellite})\n\nReturn the swir2 band for the given sensor.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.dn_scale","page":"Home","title":"SatelliteDataSources.dn_scale","text":"dn_scale(::Type{AbstractSatellite}, layer::Symbol)\n\nReturn the scale factor applied to digital numbers.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.dn_offset","page":"Home","title":"SatelliteDataSources.dn_offset","text":"dn_offset(::Type{AbstractSatellite}, layer::Symbol)\n\nReturn the offset factor applied to digital numbers.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.decode","page":"Home","title":"SatelliteDataSources.decode","text":"decode(s::Type{AbstractSatellite}, raster::Rasters.AbstractRaster)\ndecode(s::Type{AbstractSatellite}, raster::Rasters.AbstractRasterStack)\n\nDecode the Digital Number (DN) values in the given raster(s). Typically, the decoded values will be in either reflectance (visual bands) or Kelvin (thermal bands).\n\nParameters\n\ns: The AbstractSatellite that produced the raster(s) in question.\nraster: Either a Rasters.Raster or Rasters.RasterStack to be decoded.\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.encode","page":"Home","title":"SatelliteDataSources.encode","text":"encode(s::Type{AbstractSatellite}, raster::Rasters.AbstractRaster; encoding_type=UInt16, missingval=0x0000)\nencode(s::Type{AbstractSatellite}, raster::Rasters.AbstractRasterStack; kwargs...)\n\nEncode the provided raster(s) to Digital Numbers (DN).\n\nParameters\n\ns: The AbstractSatellite that produced the raster(s) in question.\nraster: Either a Rasters.Raster or Rasters.RasterStack to be encoded.\nencoding_type: The Julia type to use for storing the encoded values (default = UInt16).\nmissingval: The value to denote missing values (default = 0x0000).\n\n\n\n\n\n","category":"function"},{"location":"#SatelliteDataSources.metadata","page":"Home","title":"SatelliteDataSources.metadata","text":"metadata(x::AbstractSatellite)\n\nParses the metadata fields for the given satellite scene.\n\nMetadata varies between products, but typically includes the acquisition date and processing level.\n\n\n\n\n\n","category":"function"},{"location":"#Rasters.Raster","page":"Home","title":"Rasters.Raster","text":"Raster(x::AbstractSatellite, layer::Symbol; kwargs...)\n\nRead a single layer into a Rasters.Raster.\n\nParameters\n\nx: An AbstractSatellite from which to read a layer.\nlayer: The layer to be read. See layers(s) for a list of available layers for sensor s.\nkwargs: Refer to the Rasters.Raster documentation for a summary of supported keywords.\n\n\n\n\n\n","category":"type"},{"location":"#Rasters.RasterStack","page":"Home","title":"Rasters.RasterStack","text":"RasterStack(x::AbstractSatellite, layers=bands(T); kwargs...)\n\nRead multiple layers into a Rasters.RasterStack.\n\nParameters\n\nx: An AbstractSatellite from which to read a layer.\nlayer: The layer to be read. See layers(s) for a list of available layers for sensor s.\nkwargs: Refer to the Rasters.RasterStack documentation for a summary of supported keywords.\n\n\n\n\n\n","category":"type"},{"location":"#Visualization","page":"Home","title":"Visualization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Remotely sensed imagery is typically encoded as either UInt16 or Int16 values. However, many products only actually use the first 12 bits for storing information. The result is that naive visualization methods will produce a near-black image, since the maximum possible brightness will be located in the lower range of values provided by the 16 bit encoding. To address this, we need to perform a linear stretch before visualizing an image. Moreover, many satellites have more than three bands, which motivates the use of band combinations to emphasize certain features and land cover types.","category":"page"},{"location":"","page":"Home","title":"Home","text":"visualize\ntrue_color\ncolor_infrared\nswir\nagriculture\ngeology","category":"page"},{"location":"#RemoteSensingToolbox.visualize","page":"Home","title":"RemoteSensingToolbox.visualize","text":"visualize(g::AbstractRaster; lower=0.02, upper=0.98)\nvisualize(r::AbstractRaster, g::AbstractRaster, b::AbstractRaster; lower=0.02, upper=0.98)\n\nVisualize an RGB or grayscale satellite image.\n\nReturns an Array of either RGB{N0f8} or Gray{N0f8} elements.\n\nKeywords\n\nlower: The lower percentile to use for adjusting the image histogram.\nupper: The upper percentile to use for adjusting the image histogram.\n\nExample\n\nusing RemoteSensingToolbox, ArchGDAL, Rasters, FileIO, JpegTurbo\n\n# Prepare a Landsat 8 Image\nsrc = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1\")\n\n# Display True Color Image\nr, g, b = RasterStack(src, [:red, :green, :blue])\nimg = visualize(r, g, b; upper=0.90)\nFileIO.save(\"truecolor.jpg\", img)\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.true_color","page":"Home","title":"RemoteSensingToolbox.true_color","text":"true_color(src::AbstractSatellite; lower=0.02, upper=0.98)\ntrue_color(s::Type{AbstractSatellite}, raster::AbstractRasterStack; lower=0.02, upper=0.98)\n\nVisualize a satellite image using the true-color band combination, which appears like a natural image.\n\nAccepts either an AbstractSatellite or a combination of Type{AbstractSatellite} and AbstractRasterStack.\n\nReturns an Array of either RGB{N0f8} or Gray{N0f8} elements.\n\nKeywords\n\nlower: The lower percentile to use for adjusting the image histogram.\nupper: The upper percentile to use for adjusting the image histogram.\n\nExample\n\nusing RemoteSensingToolbox, ArchGDAL, Rasters\n\n# Prepare a Landsat 8 Image\nsrc = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1\")\n\n# Read Bands Directly from Disk\ntrue_color(src; upper=0.90)\n\n# Read Bands from a RasterStack\nstack = RasterStack(src; lazy=true)\ntrue_color(Landsat8, stack; upper=0.90)\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.color_infrared","page":"Home","title":"RemoteSensingToolbox.color_infrared","text":"color_infrared(src::AbstractSatellite; lower=0.02, upper=0.98)\ncolor_infrared(s::Type{AbstractSatellite}, raster::AbstractRasterStack; lower=0.02, upper=0.98)\n\nVisualize a satellite image using the color-infrared band combination, which highlight vegetation in red, water in blue, and urban areas in grey.\n\nAccepts either an AbstractSatellite or a combination of Type{AbstractSatellite} and AbstractRasterStack.\n\nReturns an Array of either RGB{N0f8} or Gray{N0f8} elements.\n\nKeywords\n\nlower: The lower percentile to use for adjusting the image histogram.\nupper: The upper percentile to use for adjusting the image histogram.\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.swir","page":"Home","title":"RemoteSensingToolbox.swir","text":"swir(src::AbstractSatellite; lower=0.02, upper=0.98)\nswir(s::Type{AbstractSatellite}, raster::AbstractRasterStack; lower=0.02, upper=0.98)\n\nVisualize a satellite image using the SWIR band combination, which emphasizes dense vegetation as dark green.\n\nAccepts either an AbstractSatellite or a combination of Type{AbstractSatellite} and AbstractRasterStack.\n\nReturns an Array of either RGB{N0f8} or Gray{N0f8} elements.\n\nKeywords\n\nlower: The lower percentile to use for adjusting the image histogram.\nupper: The upper percentile to use for adjusting the image histogram.\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.agriculture","page":"Home","title":"RemoteSensingToolbox.agriculture","text":"agriculture(src::AbstractSatellite; lower=0.02, upper=0.98)\nagriculture(s::Type{AbstractSatellite}, raster::AbstractRasterStack; lower=0.02, upper=0.98)\n\nVisualize a satellite image with the agricultural band combination, which is used for crop monitoring and emphasizes healthy vegetation.\n\nAccepts either an AbstractSatellite or a combination of Type{AbstractSatellite} and AbstractRasterStack.\n\nReturns an Array of either RGB{N0f8} or Gray{N0f8} elements.\n\nKeywords\n\nlower: The lower percentile to use for adjusting the image histogram.\nupper: The upper percentile to use for adjusting the image histogram.\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.geology","page":"Home","title":"RemoteSensingToolbox.geology","text":"geology(src::AbstractSatellite; lower=0.02, upper=0.98)\ngeology(s::Type{AbstractSatellite}, raster::AbstractRasterStack; lower=0.02, upper=0.98)\n\nVisualize a satellite image with the geology band combination, which emphasizes geological formations, lithology features, and faults.\n\nAccepts either an AbstractSatellite or a combination of Type{AbstractSatellite} and AbstractRasterStack.\n\nReturns an Array of either RGB{N0f8} or Gray{N0f8} elements.\n\nKeywords\n\nlower: The lower percentile to use for adjusting the image histogram.\nupper: The upper percentile to use for adjusting the image histogram.\n\n\n\n\n\n","category":"function"},{"location":"#Land-Cover-Indices","page":"Home","title":"Land Cover Indices","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Land cover indices are used to highlight different types of land cover. For example, the Modified Normalized Difference Water Index (MNDWI) is used to highlight water while diminishing built-up areas. Each index is  expressed as a function of two or more bands. RemoteSensingToolbox can automatically select the appropriate  bands for a given index by specifying the AbstractSatellite type, while also providing the option to manually specify bands as the user desires.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"indices.jl\"]\nPrivate = false","category":"page"},{"location":"#RemoteSensingToolbox.mndwi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.mndwi","text":"mndwi(src::AbstractSatellite)\nmndwi(::Type{AbstractSatellite}, stack::AbstractRasterStack)\nmndwi(green::AbstractRaster, swir::AbstractRaster)\n\nCompute the Modified Normalised Difference Water Index (Xu 2006).\n\nMNDWI = (green - swir) / (green + swir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.nbri-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.nbri","text":"nbri(src::AbstractSatellite)\nnbri(::Type{AbstractSatellite}, stack::AbstractRasterStack)\nnbri(nir::AbstractRaster, swir2::AbstractRaster)\n\nCompute the Normalized Burn Ratio Index.\n\nNBRI is used to emphasize burned areas.\n\nNBRI = (nir - swir2) / (nir + swir2)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndbi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndbi","text":"ndbi(src::AbstractSatellite)\nndbi(::Type{AbstractSatellite}, stack::AbstractRasterStack)\nndbi(swir1::AbstractRaster, nir::AbstractRaster)\n\nCompute the The Normalized Difference Built-up Index\n\nNDBI is used to emphasize urban and built-up areas.\n\nNDBI = (swir1 - nir) / (swir1 + nir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndmi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndmi","text":"ndmi(src::AbstractSatellite)\nndmi(::Type{AbstractSatellite}, stack::AbstractRasterStack)\nndmi(nir::AbstractRaster, swir1::AbstractRaster)\n\nCompute the Normalized Difference Moisture Index.\n\nNDMI is sensitive to the moisture levels in vegetation. It is used to monitor droughts and fuel levels in fire-prone areas.\n\nNDMI = (nir - swir1) / (nir + swir1)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndvi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndvi","text":"ndvi(src::AbstractSatellite)\nndvi(::Type{AbstractSatellite}, stack::AbstractRasterStack)\nndvi(nir::AbstractRaster, red::AbstractRaster)\n\nCompute the Normalized Difference Vegetation Index.\n\nNDVI = (nir - red) / (nir + red)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.ndwi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.ndwi","text":"ndwi(src::AbstractSatellite)\nndwi(::Type{AbstractSatellite}, stack::AbstractRasterStack)\nndwi(green::AbstractRaster, nir::AbstractRaster)\n\nCompute the Normalized Difference Water Index (McFeeters 1996).\n\nNDWI = (green - nir) / (green + nir)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.savi-Tuple{Rasters.AbstractRaster, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.savi","text":"savi(src::AbstractSatellite; L=0.33)\nsavi(::Type{AbstractSatellite}, stack::AbstractRasterStack; L=0.33)\nsavi(nir::AbstractRaster, red::AbstractRaster; L=0.33, scale=1.0, offset=0.0)\n\nCompute the Soil Adjusted Vegetation Index (Huete 1988).\n\nSAVI is a vegetation index which attempts to minimize soil brightness influences by introducing a soil-brightness correction factor (L).\n\nSAVI = ((nir - red) / (nir + red + L)) * (1 + L)\n\nKeywords\n\nL: The ammount of vegetative cover, where 1.0 means no vegetation and 0.0 means high vegetation.\nscale: The scaling factor to convert digital numbers to reflectance.\noffset: The offset to convert digital numbers to reflectance.\n\n\n\n\n\n","category":"method"},{"location":"#Spectral-Analysis","page":"Home","title":"Spectral Analysis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Spectral analysis involves studying the relationships between different materials and their corresponding  spectral signatures. Due to the interactions between light and matter, each signature is unique to the material that emitted it. We can exploit this fact to assign a label to each pixel, or even estimate the abundances of different materials at a sub-pixel level. This package provides several methods for both extracting and  visualizing these signatures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"extract_signatures\nplot_signatures\nplot_signatures!","category":"page"},{"location":"#RemoteSensingToolbox.extract_signatures","page":"Home","title":"RemoteSensingToolbox.extract_signatures","text":"function extract_signatures([agg], raster, shp, label::Symbol)\n\nExtract signatures from a Raster or RasterStack within regions specified by a provided shapefile.\n\nParameters\n\nagg: A function to aggregate signatures belonging to the same class (ex. mean, median, maximum).\nraster: An AbstractRaster or AbstractRasterStack from which to extract the spectral signatures.\nshp: A table with a :geometry column of GeoInterface.jl geometries and land cover labels.\nlabel: The column in shp corresponding to the land cover type.\n\nReturns\n\nA Tables.columntable containing all labelled signatures or their aggregation if agg is provided.\n\nExample\n\njulia> src = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\");\n\njulia> sr = decode(Landsat8, RasterStack(src, [:B1, :B2, :B3, :B4, :B5]));\n\njulia> shp = GeoDataFrames.read(\"data/landcover/landcover.shp\");\n\njulia> extract_signatures(sr, shp, :C_name) |> DataFrame\n1925×6 DataFrame\n  Row │ label      B1         B2         B3        B4        B5       \n      │ String     Float32    Float32    Float32   Float32   Float32  \n──────┼───────────────────────────────────────────────────────────────\n    1 │ Hail Scar  0.058005   0.10613    0.19028   0.25177   0.51577\n    2 │ Hail Scar  0.057895   0.10888    0.19358   0.257215  0.520198\n    3 │ Hail Scar  0.06026    0.111795   0.197265  0.263045  0.523855\n    4 │ Hail Scar  0.0595175  0.109375   0.195257  0.258315  0.522287\n    5 │ Hail Scar  0.059215   0.108468   0.191655  0.254327  0.51401\n  ⋮   │     ⋮          ⋮          ⋮         ⋮         ⋮         ⋮\n 1921 │ Built Up   0.0633125  0.0914725  0.145565  0.165227  0.255153\n 1922 │ Built Up   0.0764025  0.100878   0.154392  0.176063  0.24363\n 1923 │ Built Up   0.09788    0.126342   0.180738  0.19941   0.25958\n 1924 │ Built Up   0.0973025  0.133163   0.1894    0.198475  0.278775\n 1925 │ Built Up   0.06345    0.089685   0.145042  0.158243  0.272505\n                                                     1915 rows omitted\n\njulia> extract_signatures(mean, sr, shp, :C_name) |> DataFrame\n7×6 DataFrame\n Row │ label       B1          B2          B3         B4          B5       \n     │ String      Float32     Float32     Float32    Float32     Float32  \n─────┼─────────────────────────────────────────────────────────────────────\n   1 │ Hail Scar   0.0618124   0.107894    0.187857   0.24683     0.507976\n   2 │ Bare Earth  0.0484324   0.053983    0.0775185  0.0886341   0.231951\n   3 │ Road        0.0400183   0.0534427   0.0938634  0.0958244   0.245025\n   4 │ Lake        0.00137886  0.00423271  0.0135606  0.00652965  0.031825\n   5 │ Trees       0.0183338   0.0203976   0.0401544  0.024148    0.318622\n   6 │ Vegetation  0.00441971  0.0157759   0.0787841  0.0463343   0.495117\n   7 │ Built Up    0.0845031   0.113944    0.174032   0.197151    0.283717\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.plot_signatures","page":"Home","title":"RemoteSensingToolbox.plot_signatures","text":"plot_signatures(bandset::Type{<:AbstractSatellite}, sigs; kwargs...)\nplot_signatures(bandset::Vector{<:Pair}, sigs; colors=Makie.wong_colors(), label=:label)\n\nPlot the spectral signatures for one or more land cover types.\n\nParameters\n\nbandset: An AbstractSatellite or a vector of sorted band => wavelength pairs.\nsigs: A table whose rows consist of spectral signatures and their associated labels.\n\nKeywords\n\nlabel: The column in sigs containing the signature labels (default = :label).\ncolors: The color scheme used by the plot (default = Makie.wong_colors()).\n\nExample\n\njulia> src = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1\");\n\njulia> surface_reflectance = decode(Landsat8, RasterStack(src));\n\njulia> shp = GeoDataFrames.read(\"data/landcover/landcover.shp\");\n\njulia> sigs = extract_signatures(mean, surface_reflectance, shp, :MC_name);\n\njulia> plot_signatures(Landsat8, sigs, colors=[:brown, :orange, :blue, :green])\n\n\n\n\n\n","category":"function"},{"location":"#RemoteSensingToolbox.plot_signatures!","page":"Home","title":"RemoteSensingToolbox.plot_signatures!","text":"plot_signatures!(ax, bandset::Type{<:AbstractSatellite}, sigs; kwargs...)\nplot_signatures!(ax, bandset::Vector{<:Pair}, sigs; colors=Makie.wong_colors(), label=:label)\n\nPlot the spectral signatures for one or more land cover types onto an existing Makie.Axis.\n\nParameters\n\nax: The Makie.Axis onto which to plot the signatures.\nbandset: An AbstractSatellite or a vector of sorted band => wavelength pairs.\nsigs: A table whose rows consist of spectral signatures and their associated labels.\n\nKeywords\n\nlabel: The column in sigs containing the signature labels (default = :label).\ncolors: The color scheme used by the plot (default = Makie.wong_colors()).\n\nExample\n\nusing RemoteSensingToolbox, Rasters, GeoDataFrames, Statistics, CairoMakie\n\n# Read Images And Convert DNs To Reflectance\nlandsat = Landsat8(\"data/LC08_L2SP_043024_20200802_20200914_02_T1/\")\nsentinel = Sentinel2{20}(\"data/T11UPT_20200804T183919/\")\nlandsat_reflectance = decode(Landsat8, RasterStack(landsat))\nsentinel_reflectance = decode(Sentinel2, RasterStack(sentinel))\n\n# Read Landcover Labels From Shapefile\nshp = GeoDataFrames.read(\"data/landcover/landcover.shp\")\n\n# Extract Average Spectral Signature For Each Landcover Type\nlandsat_sigs = extract_signatures(mean, landsat_reflectance, shp, :MC_name)\nsentinel_sigs = extract_signatures(mean, sentinel_reflectance, shp, :MC_name)\n\n# Create Figure and Axis\nfig = Figure(resolution=(800,550));\nax1 = Axis(fig[1,1], ylabel=\"Reflectance\", title=\"Landsat Signatures\")\nax2 = Axis(fig[2,1], xlabel=\"Wavelength (nm)\", ylabel=\"Reflectance\", title=\"Sentinel Signatures\")\n\n# Plot Signatures\nplot_signatures!(ax1, Landsat8, landsat_sigs, colors=[:brown, :orange, :blue, :green])\nplot_signatures!(ax2, Sentinel2{20}, sentinel_sigs, colors=[:brown, :orange, :blue, :green])\n\n# Add Legend\nLegend(fig[:,2], ax1)\n\n\n\n\n\n","category":"function"},{"location":"#Principal-Component-Analysis","page":"Home","title":"Principal Component Analysis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Principal Component Analysis (PCA) is typically used to reduce the dimensionality of data. In the case of remote sensing, we are interested in reducing the number of bands we need to store while retaining as much information as possible. PCA rotates the bands into a new coordinate space where each band, called a principal component, is orthogonal to and uncorrelated with every other component. By convention, we order the bands in the transformed image in terms of their explained variance, such that the nth component accounts for more variance than any component after it.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"pca.jl\"]\nPrivate = false","category":"page"},{"location":"#RemoteSensingToolbox.PCA","page":"Home","title":"RemoteSensingToolbox.PCA","text":"Remotely sensed imagery typically consists of anywhere from four to several hundred spectral bands. These bands are often highly correlated due to occupying similar spectral regions. Principal Component Analysis (PCA) is used in remote sensing to:\n\nCreate a smaller dataset from multiple bands, while retaining as much of the original spectral information as possible. The new image will consist of several uncorrelated PC bands.\nReveal complex relationships among spectral features.\nDistinguish between characteristics that are prevalent in most bands and those that are specific to only a few.\n\nExample\n\njulia> desis = DESIS(\"DESIS-HSI-L2A-DT0884573241_001-20200601T234520-V0210/\");\n\njulia> desis_bands = Raster(desis, :Bands)\n\njulia> pca = fit_pca(desis_bands, stats_fraction=0.1)\nPCA(dimensions=235) \n\nProjection Matrix:\n235×235 Matrix{Float32}:\n  0.0001  0.0032   0.0016  -0.0094   0.0147  -0.0151  -0.0049   0.0163  …   0.0038  -0.0012   0.0008  -0.0032  -0.0007   0.0053\n  0.0005  0.0099   0.0042  -0.0244   0.0517  -0.0335  -0.0185   0.0441     -0.0023  -0.0016  -0.0008   0.001    0.0003  -0.0004\n  0.0003  0.015    0.0053  -0.037    0.133   -0.0443  -0.0271   0.1381     -0.0006   0.0004   0.0002  -0.0006   0.0003   0.0002\n  0.0003  0.019    0.0071  -0.0385   0.1369  -0.0393  -0.0148   0.0949     -0.0008   0.0006  -0.0001  -0.0006   0.0001  -0.0006\n  0.0003  0.0232   0.0073  -0.0419   0.1469  -0.037    0.0041   0.0839     -0.0013  -0.0025   0.0005   0.0007   0.0007  -0.0002\n  0.0001  0.0267   0.0077  -0.0461   0.1713  -0.0325   0.0246   0.0861  …   0.0013  -0.0007  -0.0007   0.0024  -0.0012  -0.0028\n  0.0001  0.0295   0.0083  -0.0476   0.1695  -0.0348   0.0319   0.0827     -0.0015  -0.0016  -0.0029   0.0004   0.0019  -0.0009\n -0.0001  0.0318   0.0086  -0.0482   0.17    -0.0352   0.0414   0.0784      0.0005  -0.002    0.0003   0.0021  -0.0003  -0.0022\n  ⋮                                           ⋮                         ⋱            ⋮                                  \n -0.0663  0.0371  -0.1728   0.0196  -0.0508  -0.1394  -0.0054  -0.0226     -0.0003   0.0001   0.0007  -0.0009  -0.0002   0.0004\n -0.0658  0.0365  -0.1679   0.0204  -0.0717  -0.1474  -0.0087  -0.0193     -0.0006   0.0002   0.0004  -0.0      0.0004  -0.0001\n -0.0655  0.0352  -0.163    0.0193  -0.0767  -0.1511  -0.012   -0.0232     -0.0005   0.0002  -0.0004  -0.0001  -0.0002   0.0005\n -0.066   0.035   -0.1618   0.0193  -0.0859  -0.1503  -0.0055  -0.0177  …   0.0003   0.0005   0.001   -0.0      0.0003  -0.0002\n -0.067   0.035   -0.1619   0.019   -0.0745  -0.1466   0.0245  -0.0228     -0.0001   0.0002  -0.0002  -0.0001  -0.0002   0.0005\n -0.0679  0.0343  -0.1601   0.0176  -0.0721  -0.139    0.0328  -0.0286      0.0003   0.0003   0.0005  -0.0      0.0003   0.0002\n -0.0682  0.0337  -0.1588   0.0151  -0.0458  -0.1242   0.0549  -0.0315      0.0002  -0.0002  -0.0003   0.0002  -0.0003  -0.0005\n -0.0711  0.0343  -0.1601   0.012   -0.0612  -0.1804   0.2151  -0.0971      0.0004  -0.0001   0.0      0.0003   0.0     -0.0003\n\nImportance of Components:\n  Cumulative Variance: 0.8782  0.9493  0.9809  0.9869  0.9889  0.9906  0.9915  0.9922  0.9928  ...  1.0\n  Explained Variance: 0.8782  0.0711  0.0316  0.006  0.0021  0.0017  0.0009  0.0007  0.0006  ...  0.0\n\njulia> transformed = forward_pca(pca, desis_bands, 12);\n\njulia> size(transformed)\n(1131, 1120, 12)\n\njulia> recovered = inverse_pca(pca, transformed);\n\njulia> size(recovered)\n(1131, 1120, 235)\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.cumulative_variance-Tuple{PCA}","page":"Home","title":"RemoteSensingToolbox.cumulative_variance","text":"cumulative_variance(x::PCA)\n\nReturn the cumulative variance associated with each principal component of the fitted PCA transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.explained_variance-Tuple{PCA}","page":"Home","title":"RemoteSensingToolbox.explained_variance","text":"explained_variance(x::PCA)\n\nReturn the explained variance associated with each principal component of the fitted PCA transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.fit_pca-Tuple{Union{Rasters.AbstractRaster, Rasters.AbstractRasterStack}}","page":"Home","title":"RemoteSensingToolbox.fit_pca","text":"fit_pca(raster::Union{<:AbstractRasterStack, <:AbstractRaster}; method=:cov, stats_fraction=1.0)\nfit_pca(signatures::Matrix{Float32}; method=:cov, stats_fraction=1.0)\n\nFit a Principal Component Analysis (PCA) transformation to the given raster or spectral signatures.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack on which to fit the PCA transformation.\nsignatures: An nxb matrix of spectral signatures where n is the number of signatures and b is the number of bands.\n\nKeywords\n\nmethod: Either :cov or :cor, depending on whether we want to use the covariance or correlation matrix for computing the PCA rotation.\nstats_fraction: The fraction of pixels to use when computing the covariance (or correlation) matrix. Values less than 1.0 will speed up computation at the cost of precision.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.forward_pca-Tuple{PCA, Rasters.AbstractRasterStack, Int64}","page":"Home","title":"RemoteSensingToolbox.forward_pca","text":"forward_pca(transformation::PCA, raster::Union{<:AbstractRaster, <:AbstractRasterStack}, components::Int)\nforward_pca(transformation::PCA, signatures::Matrix, components::Int)\n\nPerform a forward Principal Component Analysis (PCA) rotation while retaining only the specified number of components.\n\nParameters\n\ntransformation: A previously fitted PCA transformation.\nraster: The AbstractRaster or AbstractRasterStack on which to perform the PCA transformation.\nsignatures: An nxb matrix of signatures where n is the number of signatures and b is the number of bands.\ncomponents: The number of bands to retain in the transformed image or signatures.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.inverse_pca-Tuple{PCA, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.inverse_pca","text":"inverse_pca(transformation::PCA, raster::AbstractRaster)\ninverse_pca(transformation::PCA, signatures::Matrix)\n\nPerform an inverse Principal Component Analysis (PCA) transformation to recover the original image.\n\nParameters\n\ntransformation: A previously fitted PCA transformation.\nraster: An AbstractRaster representing a previously transformed image.\nsignatures: An nxc matrix of previously transformed signatures where n is the number of signatures and c is the number of components.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.projection-Tuple{PCA}","page":"Home","title":"RemoteSensingToolbox.projection","text":"projection(x::PCA)\n\nReturn the projection matrix for the fitted PCA transformation.\n\n\n\n\n\n","category":"method"},{"location":"#Minimum-Noise-Fraction","page":"Home","title":"Minimum Noise Fraction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The Minimum Noise Fraction (MNF) transformation is used to separate noise from data along the spectral dimension. This method is typically used with hyperspectral imagery, both as a means of dimension reduction and for noise removal. The transformed image will have its bands placed in descending order according to their Signal to Noise Ratio (SNR). The result is that the noise becomes concentrated in the higher bands, which can then be removed by either applying a standard image denoising algorithm or dropping them altogether.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"mnf.jl\"]\nPrivate = false","category":"page"},{"location":"#RemoteSensingToolbox.MNF","page":"Home","title":"RemoteSensingToolbox.MNF","text":"The Minimum Noise Fraction (MNF) transform is a linear transformation used to reduce the spectral dimensionality of image data and  segregate noise. MNF consists of two separate principal component rotations. The first rotation uses the principal components  of the noise covariance matrix to decorrelate and rescale the noise (a process known as noise whitening), resulting in a transformed  image in which the noise has unit variance and no band-to-band correlations. The second rotation is a standard PCA rotation  applied to the noise-whitened image.\n\nThe bands in the transformed image will be ordered according to their Signal to Noise Ratio (SNR), with the highest SNR being  placed first. The result is that the noise becomes concentrated in the higher bands. Thus, the transform can be used to separate  noise from data by performing a forward transform, determining which bands contain coherent images, and running an inverse  transform after either discarding or denoising the remaining bands. The number of bands to keep in the inverse transform can be determined by a number  of methods. The simplest approach is to look at the sorted transformed bands and threshold at the band where no recognizable  features can be observed. An alternative method is to threshold at a desired cumulative SNR.\n\nExample\n\njulia> src = DESIS(\"data/DESIS-HSI-L2A-DT0485529167_001-20220712T223540-V0220\")\n\njulia> desis = decode(DESIS, Raster(src, :Bands))\n\njulia> roi = @view desis[X(1019:1040), Y(550:590)];\n\njulia> mnf = fit_mnf(desis, roi)\nMNF(dimensions=235) \n\nProjection Matrix:\n235×235 Matrix{Float32}:\n -2.135    2.3502   0.3612   0.5912   0.5217  -0.0917   0.0043  …   0.0002  -0.0001  -0.0004  -0.0004  -0.0      0.0004\n -0.0959   0.0422  -0.0047  -0.2362  -0.3962  -0.2313  -0.1685      0.0001   0.0004   0.0002   0.0003   0.0001  -0.0001\n  0.0043   0.0058  -0.0032   0.0023  -0.0061  -0.0048   0.0028     -0.0001   0.0001  -0.0001  -0.0      0.0      0.0001\n  0.0039   0.002   -0.002    0.0012  -0.0032  -0.004    0.006      -0.0006   0.0002  -0.0001  -0.0     -0.0003  -0.0\n  0.0024   0.0018  -0.003   -0.0008   0.0038  -0.0003   0.0057      0.0009  -0.0007   0.0002  -0.0012   0.0012  -0.0\n  0.0019  -0.003    0.0038  -0.002   -0.0001  -0.0003  -0.0     …   0.0021   0.0009  -0.0004   0.0014  -0.0011  -0.0006\n  0.0047   0.0055   0.006   -0.0014  -0.0011   0.0021   0.0053     -0.0035   0.0006   0.0002  -0.0026   0.0014   0.0019\n  0.0072   0.0042   0.0012   0.0016   0.0011  -0.002   -0.001       0.0     -0.0026   0.0012   0.0034  -0.0006  -0.0009\n  ⋮                                            ⋮                ⋱            ⋮                                  \n -0.0004  -0.0012   0.0007   0.0006  -0.0      0.0002   0.0005      0.0005   0.0002  -0.0004  -0.0002  -0.0001   0.0001\n -0.0014  -0.0005  -0.0005   0.0019  -0.0002  -0.0005   0.0017      0.0003   0.0005   0.0      0.0004   0.0005   0.0\n -0.0004   0.0008  -0.0003   0.0013   0.0004   0.0014   0.0004      0.0002  -0.0001   0.0002   0.0001  -0.0002  -0.0002\n -0.0008  -0.0015   0.0021  -0.0004  -0.0004   0.0012   0.0006  …  -0.0011   0.0002  -0.0007   0.0001   0.0005  -0.0001\n  0.0008  -0.0004   0.0009   0.0019  -0.0022  -0.0014   0.0013      0.0003  -0.0001  -0.0003  -0.0      0.0003   0.0002\n  0.0005   0.0006  -0.0022  -0.0003   0.0     -0.0022   0.0016     -0.001    0.0002  -0.0003   0.0003  -0.0005   0.0005\n  0.001   -0.0005  -0.0007   0.0025  -0.0019   0.0005   0.0015      0.0002  -0.0005   0.0     -0.0005   0.0002  -0.0002\n -0.0003   0.0002  -0.0021  -0.0008  -0.0012   0.0003   0.0003     -0.0001  -0.0      0.0001   0.0      0.0      0.0\n\nComponent Statistics:\n  Eigenvalues: 7975.439  4040.6348  2092.866  717.8178  468.5496  247.5029  202.2003  176.8452  87.3302  ...  0.3602\n  Cumulative Eigenvalues: 0.4779  0.72  0.8454  0.8884  0.9165  0.9313  0.9434  0.954  0.9593  ...  1.0\n  Explained SNR: 7974.4385  4039.6353  2091.8635  716.8176  467.55  246.5022  201.1985  175.845  86.3301  ...  -0.6399\n  Cumulative SNR: 0.4839  0.729  0.856  0.8995  0.9278  0.9428  0.955  0.9657  0.9709  ...  0.9985\n\njulia> transformed = forward_mnf(mnf, desis, 12);\n\njulia> size(transformed)\n(1131, 1120, 12)\n\njulia> recovered = inverse_mnf(mnf, transformed);\n\njulia> size(recovered)\n(1131, 1120, 235)\n\n\n\n\n\n","category":"type"},{"location":"#RemoteSensingToolbox.cumulative_eigenvalues-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.cumulative_eigenvalues","text":"cumulative_eigenvalues(x::MNF)\n\nReturn the cumulative eigenvalues associated with each principal components of the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.cumulative_snr-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.cumulative_snr","text":"cumulative_snr(x::MNF)\n\nReturn the cumulative SNR associated with each principal components of the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.data_cov-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.data_cov","text":"data_cov(x::MNF)\n\nReturn the data covariance matrix for the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.eigenvalues-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.eigenvalues","text":"eigenvalues(x::MNF)\n\nReturn the eigenvalues associated with each principal components of the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.estimate_noise-Tuple{Union{Rasters.AbstractRaster, Rasters.AbstractRasterStack}}","page":"Home","title":"RemoteSensingToolbox.estimate_noise","text":"estimate_noise(raster::Union{<:AbstractRaster, <:AbstractRasterStack}; smooth=false)\n\nEstimate the noise covariance matrix for the given raster.\n\nUses the Minimum/Maximum Autocorrelation Factor proposed by Switzer and Green.\n\nFor best results, the provided raster should be spectrally homoegenous (e.g., an open field or body of water).\n\nParameters\n\nraster: An AbstractRaster or AbstractRasterStack.\nsmooth: Numerical stability requires that no bands have a variance of zero. A smoothing term can be applied to ensure that this is the case.\n\nExample\n\nusing RemoteSensingToolbox, Rasters\n\n# Load Data\nsrc = DESIS(\"DESIS-HSI-L2A-DT0485529167_001-20220712T223540-V0220\")\ndesis = decode(DESIS, Raster(src, :Bands))\n\n# Extract Homogenous Region of Interest\nroi = desis[X(1019:1040), Y(550:590)]\n\n# Estimate Noise\nncm = estimate_noise(roi, smooth=true)\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.fit_mnf-Tuple{Union{Rasters.AbstractRaster, Rasters.AbstractRasterStack}, Matrix}","page":"Home","title":"RemoteSensingToolbox.fit_mnf","text":"fit_mnf(raster, noise_sample; smooth=true)\n\nFit a Minimum Noise Fraction (MNF) transformation to the given AbstractRasterStack or AbstractRaster.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack on which to fit the MNF transformation.\nnoise_sample: A homogenous (spectrally uniform) region extracted from raster for calculating the noise covariance matrix.\nsmooth: The MNF transform cannot be computed if any band in noise_sample has zero variance. To correct this, you may wish to introduce a small smoothing term (true by default).\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.forward_mnf-Tuple{MNF, Rasters.AbstractRasterStack, Int64}","page":"Home","title":"RemoteSensingToolbox.forward_mnf","text":"forward_mnf(transformation::MNF, raster, components::Int)\nforward_mnf(transformation::MNF, sigs::Matrix, components::Int)\n\nPerform a forward Minimum Noise Fraction (MNF) rotation on the given raster or signatures, retaining only the specified number of components.\n\nParameters\n\ntransformation: A previously fitted MNF transformation.\nraster: The AbstractRaster or AbstractRasterStack on which to perform the MNF transformation.\nsigs: An n x b matrix of spectral signatures where n is the number of signatures and b is the number of bands.\ncomponents: The number of bands to retain in the transformed image. All band numbers exceeding this value will be discarded.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.inverse_mnf-Tuple{MNF, Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.inverse_mnf","text":"inverse_mnf(transformation::MNF, raster::AbstractRaster)\ninverse_mnf(transformation::MNF, sigs::Matrix)\n\nPerform an inverse Minimum Noise Fraction (MNF) transformation to recover the original image or signatures.\n\nParameters\n\ntransformation: A previously fitted MNF transformation.\nraster: An AbstractRaster representing a previously transformed image. The number of bands should be less than or equal to that of the original image.\nsigs: An n x p matrix of transformed signatures where n is the number of signatures and p is the number of retained components.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.noise_cov-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.noise_cov","text":"noise_cov(x::MNF)\n\nReturn the noise covariance matrix for the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.projection-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.projection","text":"projection(x::MNF)\n\nReturn the projection matrix for the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.snr-Tuple{MNF}","page":"Home","title":"RemoteSensingToolbox.snr","text":"snr(x::MNF)\n\nReturn the estimated SNR associated with each principal components of the fitted MNF transform.\n\n\n\n\n\n","category":"method"},{"location":"#Utilities","page":"Home","title":"Utilities","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RemoteSensingToolbox provides several utility functions for working with remotely sensed data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [RemoteSensingToolbox]\nPages = [\"utils.jl\"]\nPrivate = false","category":"page"},{"location":"#RemoteSensingToolbox.apply_masks!-Tuple{Union{Rasters.AbstractRaster, Rasters.AbstractRasterStack}, Vararg{Any}}","page":"Home","title":"RemoteSensingToolbox.apply_masks!","text":"apply_masks!(raster, masks...)\n\nSimilar to Rasters.mask!, but with the following differences:\n\nRemoves non-missing mask values instead of missing values. This is useful when working with cloud or shadow masks.\nAccepts multiple masks, which are applied in sequence.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack to be masked.\nmasks: One or more masks to apply to the given raster.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.apply_masks-Tuple{Union{Rasters.AbstractRaster, Rasters.AbstractRasterStack}, Vararg{Any}}","page":"Home","title":"RemoteSensingToolbox.apply_masks","text":"apply_masks(raster, masks...)\n\nSimilar to Rasters.mask, but with the following differences:\n\nRemoves non-missing mask values instead of missing values. This is useful when working with cloud or shadow masks.\nAccepts multiple masks, which are applied in sequence.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack to be masked.\nmasks: One or more masks to apply to the given raster.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.has_bands-Tuple{Any}","page":"Home","title":"RemoteSensingToolbox.has_bands","text":"has_bands(raster)\n\nReturns true if the provided raster or stack has a band dimension.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.mask_nan!-Tuple{Any}","page":"Home","title":"RemoteSensingToolbox.mask_nan!","text":"mask_nan!(raster)\n\nReplace all NaN values with missingval(raster) in-place.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack from which we want to drop NaN values.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.nbands-Tuple{Rasters.AbstractRaster}","page":"Home","title":"RemoteSensingToolbox.nbands","text":"nbands(raster)\n\nReturns the number of spectral bands in the given AbstractRaster or AbstractRasterStack.\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.sample-Tuple{Rasters.AbstractRasterStack}","page":"Home","title":"RemoteSensingToolbox.sample","text":"sample(raster, [sink]; fraction=0.1)\n\nRandomly sample a percentage of non-missing values from the provided raster.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack from which to sample.\nsink: A Tables.jl materializer (default =Tables.columntable).\nfraction: The fraction of values to sample (default = 10%).\n\nExample\n\njulia> src = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\");\n\njulia> rs = RasterStack(src, [:blue, :green, :red, :nir]);\n\njulia> sample(rs, DataFrame)\n4054017×4 DataFrame\n     Row │ B2      B3      B4      B5     \n         │ UInt16  UInt16  UInt16  UInt16 \n─────────┼────────────────────────────────\n       1 │   7841    9082    8174   24372\n       2 │   8117    8977    8372   15577\n       3 │  26460   26601   26579   27023\n    ⋮    │   ⋮       ⋮       ⋮       ⋮\n 4054015 │   7735    8403    7929   18386\n 4054016 │   6984    9559   10026   11986\n 4054017 │   8036    8658    8328   13896\n                      4054011 rows omitted\n\n\n\n\n\n","category":"method"},{"location":"#RemoteSensingToolbox.table","page":"Home","title":"RemoteSensingToolbox.table","text":"table(raster, [sink])\n\nConvert the raster into a table compatible with Tables.jl.\n\nReplaces all missingvals with missing.\n\nParameters\n\nraster: The AbstractRaster or AbstractRasterStack to read into a table.\nsink: A Tables.jl materializer (default =Tables.columntable).\n\nExample\n\njulia> src = Landsat8(\"LC08_L2SP_043024_20200802_20200914_02_T1/\");\n\njulia> rs = RasterStack(src, [:blue, :green, :red, :nir]);\n\njulia> table(rs, DataFrame) |> dropmissing!\n40540174×5 DataFrame\n      Row │ geometry               B2      B3      B4      B5     \n          │ Tuple…                 UInt16  UInt16  UInt16  UInt16 \n──────────┼───────────────────────────────────────────────────────\n        1 │ (544335.0, 5.84578e6)    8345    8798    8216   14454\n        2 │ (544335.0, 5.84576e6)    8064    8707    8106   15583\n        3 │ (544365.0, 5.84576e6)    8247    8858    8135   17552\n    ⋮     │           ⋮              ⋮       ⋮       ⋮       ⋮\n 40540172 │ (676365.0, 5.60968e6)    8863    9867   10164   16688\n 40540173 │ (676395.0, 5.60968e6)    8823    9684   10050   16210\n 40540174 │ (676425.0, 5.60968e6)    8934    9898   10324   16947\n                                             40540168 rows omitted\n\n\n\n\n\n","category":"function"}]
}
